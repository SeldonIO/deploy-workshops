{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Workshop - *Predicting product ratings from reviews*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workshop is focused on the creation, deployment, monitoring and management of a machine learning model for predicting product ratings from reviews.\n",
    "\n",
    "### Tom - this isn't completely relevant anymore, will change it before workshop to talk about pretrained model being used etc, so just ignore for now\n",
    "\n",
    "In this notebook we will be exploring the data, and training the machine learning model itself; in the form of a Tensorflow Keras model. We will then deploy a second Tensorflow model with differing architecture as a Canary model to demonstrate the A/B testing functionality Seldon provides. Then we will begin to add the advanced monitoring and explainability that Seldon Alibi is famed for. \n",
    "\n",
    "-----------------------------------\n",
    "Firstly, we will install and import the relevant packages which we will use throughout the exploration, training, and deployment process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install those not pre-installed on Google colab\n",
    "\n",
    "!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from transformers import TFDistilBertForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TFAutoModelForSequenceClassification, create_optimizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://kelly-seldon/nlp-ratings/review_data.csv...\n",
      "\\ [1 files][ 11.3 MiB/ 11.3 MiB]                                                \n",
      "Operation completed over 1 objects/11.3 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://kelly-seldon/nlp-ratings/review_data.csv review_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_product_ provided me with a pretty good, sec...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it protects our files and computer and very si...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like most businesses, we are always looking fo...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we believed _product_ was a great solution for...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i formerly used _product_ and was relieved to ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0   _product_ provided me with a pretty good, sec...      8\n",
       "1  it protects our files and computer and very si...      6\n",
       "2  like most businesses, we are always looking fo...      8\n",
       "3  we believed _product_ was a great solution for...      4\n",
       "4  i formerly used _product_ and was relieved to ...      6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"review_data.csv\", delimiter=\";\")\n",
    "\n",
    "df['review'] = df['review'].astype(str)\n",
    "df['rating'] = df['rating'].astype(str)\n",
    "\n",
    "rating_mapping = {\n",
    "    '1.0': 0,\n",
    "    '1.5': 1,\n",
    "    '2.0': 2,\n",
    "    '2.5': 3,\n",
    "    '3.0': 4,\n",
    "    '3.5': 5,\n",
    "    '4.0': 6, \n",
    "    '4.5': 7,\n",
    "    '5.0': 8\n",
    "}\n",
    "\n",
    "df['label'] = df['rating'].apply(lambda x: rating_mapping[x])\n",
    "df.drop(columns=['product', 'user_id', 'date_created', 'rating'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tom - I'm worried that the labels are so skewed the model won't be able to predict the lower ratings/.5 ratings well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    31721\n",
       "6    14017\n",
       "4     2645\n",
       "0      763\n",
       "2      625\n",
       "7      150\n",
       "5       27\n",
       "3       27\n",
       "1       25\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tom - did have validation split in here too, but don't think I need that if not fine-tuning the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.Dataset.from_pandas(train, preserve_index=False)\n",
    "test_ds = datasets.Dataset.from_pandas(test, preserve_index=False)\n",
    "comp_ds = datasets.DatasetDict({\"train\":train_ds,\"test\":test_ds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tom - all of this is from following the article https://huggingface.co/docs/transformers/tasks/sequence_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERT’s maximum input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['review'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832ff21ba0c14ec681487afd4cd8a5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42795568de984e8cb5ba05c1f4774c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_revs = comp_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = tokenized_revs[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = tokenized_revs[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"label\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "batches_per_epoch = len(tokenized_revs['train']) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tom - How does it know to map the labels to the correct labels in the reviews data? Without seeing the training data? There's surely a step missing here that needs adding in if not doing the fine tuning part? Does it need an argument for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_projector', 'vocab_transform', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_19', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tom - Can ignore this - another example I found online of fine-tuning DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_projector', 'vocab_transform', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_39', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=9)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "# model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 996, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"tf_distil_bert_for_sequence_classification_1\" (type TFDistilBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 730, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 742, in call  *\n            distilbert_output = self.distilbert(\n        File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        TypeError: Exception encountered when calling layer \"distilbert\" (type TFDistilBertMainLayer).\n        \n        in user code:\n        \n            File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 730, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 400, in call  *\n                embedding_output = self.embeddings(input_ids, inputs_embeds=inputs_embeds)  # (bs, seq_length, dim)\n            File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            TypeError: Exception encountered when calling layer \"embeddings\" (type TFEmbeddings).\n            \n            in user code:\n            \n                File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 122, in call  *\n                    final_embeddings = self.LayerNorm(inputs=final_embeddings)\n                File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n            \n                TypeError: Exception encountered when calling layer \"LayerNorm\" (type LayerNormalization).\n                \n                Failed to convert elements of [1, 1, None, 1] to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n                \n                Call arguments received:\n                  • inputs=tf.Tensor(shape=(None, 16, None, 768), dtype=float32)\n            \n            \n            Call arguments received:\n              • input_ids=tf.Tensor(shape=(None, 16, None), dtype=int64)\n              • position_ids=None\n              • inputs_embeds=None\n              • training=True\n        \n        \n        Call arguments received:\n          • self=tf.Tensor(shape=(None, 16, None), dtype=int64)\n          • input_ids=None\n          • attention_mask=tf.Tensor(shape=(None, 16, None), dtype=int64)\n          • head_mask=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received:\n      • self={'input_ids': 'tf.Tensor(shape=(None, 16, None), dtype=int64)', 'attention_mask': 'tf.Tensor(shape=(None, 16, None), dtype=int64)', 'labels': 'tf.Tensor(shape=(None, 16), dtype=int64)'}\n      • input_ids=None\n      • attention_mask=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=None\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bd4aa36be170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(tf_train_set.shuffle(1000).batch(16), epochs=3, batch_size=16,\n\u001b[0;32m----> 2\u001b[0;31m           validation_data=tf_test_set.shuffle(1000).batch(16))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 996, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"tf_distil_bert_for_sequence_classification_1\" (type TFDistilBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 730, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 742, in call  *\n            distilbert_output = self.distilbert(\n        File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        TypeError: Exception encountered when calling layer \"distilbert\" (type TFDistilBertMainLayer).\n        \n        in user code:\n        \n            File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\", line 730, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 400, in call  *\n                embedding_output = self.embeddings(input_ids, inputs_embeds=inputs_embeds)  # (bs, seq_length, dim)\n            File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            TypeError: Exception encountered when calling layer \"embeddings\" (type TFEmbeddings).\n            \n            in user code:\n            \n                File \"/home/seldon/anaconda3/lib/python3.7/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 122, in call  *\n                    final_embeddings = self.LayerNorm(inputs=final_embeddings)\n                File \"/home/seldon/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n            \n                TypeError: Exception encountered when calling layer \"LayerNorm\" (type LayerNormalization).\n                \n                Failed to convert elements of [1, 1, None, 1] to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n                \n                Call arguments received:\n                  • inputs=tf.Tensor(shape=(None, 16, None, 768), dtype=float32)\n            \n            \n            Call arguments received:\n              • input_ids=tf.Tensor(shape=(None, 16, None), dtype=int64)\n              • position_ids=None\n              • inputs_embeds=None\n              • training=True\n        \n        \n        Call arguments received:\n          • self=tf.Tensor(shape=(None, 16, None), dtype=int64)\n          • input_ids=None\n          • attention_mask=tf.Tensor(shape=(None, 16, None), dtype=int64)\n          • head_mask=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received:\n      • self={'input_ids': 'tf.Tensor(shape=(None, 16, None), dtype=int64)', 'attention_mask': 'tf.Tensor(shape=(None, 16, None), dtype=int64)', 'labels': 'tf.Tensor(shape=(None, 16), dtype=int64)'}\n      • input_ids=None\n      • attention_mask=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=None\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "# model.fit(tf_train_set.shuffle(1000).batch(16), epochs=3, batch_size=16,\n",
    "#           validation_data=tf_test_set.shuffle(1000).batch(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tom - Need to add accuracy metric in here too, but got error about using internal loss function meaning you can't specify additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tom - tf_test_set - the reviews has been tokenised. Does the tokeniser need embedding in the model? Otherwise a preprocesser will be needed in order to pass raw text to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/938 [=====================>........] - ETA: 4:02 - loss: 2.1695"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6b55bb352e00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_test_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mint_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(tf_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tom - from here down not used anymore - this was messing to build a custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.17513809638900274,\n",
       " 1: 0.3963441218203293,\n",
       " 2: 2.1003990758244067,\n",
       " 3: 7.2811999417504,\n",
       " 4: 8.88888888888889,\n",
       " 5: 37.03703703703704,\n",
       " 6: 205.76131687242798,\n",
       " 7: 205.76131687242798,\n",
       " 8: 222.22222222222223}"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataset into tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.from_tensor_slices((train['review'].values, train['rating'].values))\n",
    "ds_test = Dataset.from_tensor_slices((test['review'].values, test['rating'].values))\n",
    "ds_val = Dataset.from_tensor_slices((val['review'].values, val['rating'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covert categorical target variable to numeric variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct0, ct1, ct2, ct3, ct4, ct5, ct6, ct7, ct8 = np.bincount(y_train)\n",
    "total = len(df)\n",
    "\n",
    "weight_for_0 = (1 / ct0) * (total / 9.0)\n",
    "weight_for_1 = (1 / ct1) * (total / 9.0)\n",
    "weight_for_2 = (1 / ct2) * (total / 9.0)\n",
    "weight_for_3 = (1 / ct3) * (total / 9.0)\n",
    "weight_for_4 = (1 / ct4) * (total / 9.0)\n",
    "weight_for_5 = (1 / ct5) * (total / 9.0)\n",
    "weight_for_6 = (1 / ct6) * (total / 9.0)\n",
    "weight_for_7 = (1 / ct7) * (total / 9.0)\n",
    "weight_for_8 = (1 / ct8) * (total / 9.0)\n",
    "\n",
    "class_weights = {\n",
    "    0: weight_for_0, \n",
    "    1: weight_for_1, \n",
    "    2: weight_for_2, \n",
    "    3: weight_for_3,\n",
    "    4: weight_for_4,\n",
    "    5: weight_for_5,\n",
    "    6: weight_for_6,\n",
    "    7: weight_for_7,\n",
    "    8: weight_for_8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "\n",
    "int_vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vectorize_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return int_vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_train_ds = int_vectorize_text(X_train, y_train)\n",
    "int_val_ds = int_vectorize_text(X_val, y_val)\n",
    "int_test_ds = int_vectorize_text(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(33750, 150), dtype=int64, numpy=\n",
       " array([[  6,  83,  35, ...,   0,   0,   0],\n",
       "        [733,   3,  31, ...,   0,   0,   0],\n",
       "        [ 40,   4,  45, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  6,  18,  19, ...,   0,   0,   0],\n",
       "        [ 40,  57,  11, ...,   0,   0,   0],\n",
       "        [  6, 183,   5, ...,   0,   0,   0]])>,\n",
       " array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding layer**\n",
    "\n",
    "Input shape:\n",
    "2D tensor with shape: (batch_size, input_length).\n",
    "\n",
    "Output shape:\n",
    "3D tensor with shape: (batch_size, input_length, output_dim).\n",
    "\n",
    "*Do I have this right at the moment? I have input length as the vocab size... should output_dim be 9? What should it be?*\n",
    "\n",
    "input_length = Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "\n",
    "output_dim = Integer. Dimension of the dense embedding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conv1D layer**\n",
    "\n",
    "Should it not be 16 here?... filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "\n",
    "Should it not be 5 here?... kernel_size: An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.\n",
    "\n",
    "Do I need an input_shape argument? I don't know if I do as it's not the first layer? Embedding is the first layer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shape = int_train_ds[0].reshape(len(int_train_ds[0]), int_train_ds[0].shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "in_shape = (test_shape.shape[1],1)\n",
    "inputs = Input(shape=(in_shape), name='inputs_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 150, 1) dtype=float32 (created by layer 'inputs_cnn')>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(33750, 150), dtype=int64, numpy=\n",
       "array([[  6,  83,  35, ...,   0,   0,   0],\n",
       "       [733,   3,  31, ...,   0,   0,   0],\n",
       "       [ 40,   4,  45, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  6,  18,  19, ...,   0,   0,   0],\n",
       "       [ 40,  57,  11, ...,   0,   0,   0],\n",
       "       [  6, 183,   5, ...,   0,   0,   0]])>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, num_labels, input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "      layers.Embedding(vocab_size, 1024, mask_zero=True, input_shape=input_shape),\n",
    "      layers.Conv1D(1024, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "      layers.GlobalMaxPooling1D(),\n",
    "      layers.Dense(num_labels)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv1d_34. Consider increasing the input size. Received input shape [None, 150, 1, 1024] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-4c407121faeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# `vocab_size` is `VOCAB_SIZE + 1` since `0` is used additionally for padding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mint_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m int_model.compile(\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-355-34fe80b86dd0>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(vocab_size, num_labels, input_shape)\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     ])\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       raise ValueError(\n\u001b[0;32m--> 303\u001b[0;31m           \u001b[0;34mf'One of the dimensions in the output is <= 0 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m           \u001b[0;34mf'due to downsampling in {self.name}. Consider '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m           \u001b[0;34mf'increasing the input size. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv1d_34. Consider increasing the input size. Received input shape [None, 150, 1, 1024] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "# `vocab_size` is `VOCAB_SIZE + 1` since `0` is used additionally for padding.\n",
    "int_model = create_model(vocab_size=VOCAB_SIZE + 1, num_labels=9, input_shape=in_shape)\n",
    "int_model.compile(\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "history = int_model.fit(\n",
    "    inputs, \n",
    "    int_train_ds[1], \n",
    "#     validation_data=(int_val_ds[0], int_val_ds[1]), \n",
    "    epochs=15,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'accuracy']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8,1])\n",
    "        else:\n",
    "            plt.ylim([0,1])\n",
    "\n",
    "        plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 1.5388 - accuracy: 0.5240\n",
      "Int model accuracy: 52.40%\n"
     ]
    }
   ],
   "source": [
    "int_loss, int_accuracy = int_model.evaluate(int_test_ds[0], int_test_ds[1])\n",
    "\n",
    "print(\"Int model accuracy: {:2.2%}\".format(int_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-12.551326   -14.205595   -10.307593    -6.996902    -6.236613\n",
      "  -11.317929    14.247541     0.38065982  15.718541  ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = int_model.predict(int_test_ds[0])\n",
    "print(predictions[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-12.551326   -14.205595   -10.307593   ...  14.247541     0.38065982\n",
      "   15.718541  ]\n",
      " [ -2.5539522  -11.087661     2.168796   ...   0.59642243  -8.97046\n",
      "    5.491527  ]\n",
      " [-14.290668   -13.789915    -4.7460256  ...  11.998764     1.4773175\n",
      "   13.5251255 ]\n",
      " ...\n",
      " [-16.912428   -18.866726   -10.535642   ...   7.2865367   -3.2117934\n",
      "   10.618746  ]\n",
      " [ -7.1668673  -10.601623    -6.650805   ...  -4.0072656   -5.804961\n",
      "   -0.5142288 ]\n",
      " [ -3.5702062   -6.9096284   -2.2240076  ...  -1.6571041   -4.138695\n",
      "    0.28596228]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_re = int_test_ds[1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val_list = []\n",
    "pred_val_list = []\n",
    "\n",
    "for i in range(0,len(test_re)):\n",
    "    test_val = test_re[i]\n",
    "    test_val_list.append(test_val)\n",
    "    pred_val = list(predictions[i]).index(predictions[i].max())\n",
    "    pred_val_list.append(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(\n",
    "        {'Test_val':test_val_list,\n",
    "            'Pred_val':pred_val_list}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_val</th>\n",
       "      <th>Pred_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Test_val  Pred_val\n",
       "0            2         8\n",
       "1            6         8\n",
       "2            8         8\n",
       "3            8         8\n",
       "4            8         6\n",
       "...        ...       ...\n",
       "4995         8         8\n",
       "4996         8         6\n",
       "4997         8         8\n",
       "4998         6         8\n",
       "4999         4         8\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['match']='False'\n",
    "df_results.loc[df_results['Test_val']==df_results['Pred_val'],'match'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_results.groupby(['Test_val','match']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    0.6066\n",
       "6    0.3024\n",
       "4    0.0510\n",
       "0    0.0196\n",
       "2    0.0166\n",
       "7    0.0024\n",
       "3    0.0008\n",
       "5    0.0004\n",
       "1    0.0002\n",
       "Name: Pred_val, dtype: float64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['Pred_val'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Pred_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_val</th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>False</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>False</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>False</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>False</th>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>False</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>False</th>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>False</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>False</th>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Pred_val\n",
       "Test_val match          \n",
       "0        False        55\n",
       "         True         26\n",
       "1        False         1\n",
       "2        False        46\n",
       "         True          5\n",
       "4        False       246\n",
       "         True         37\n",
       "5        False         1\n",
       "         True          1\n",
       "6        False       901\n",
       "         True        472\n",
       "7        False        14\n",
       "         True          1\n",
       "8        False      1116\n",
       "         True       2078"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
