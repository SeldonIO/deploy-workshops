{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Workshop - *Predicting product ratings from reviews*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workshop is focused on the creation, deployment, monitoring and management of a machine learning model for predicting product ratings from reviews.\n",
    "\n",
    "In this notebook we will be exploring the data, and going through the steps to train the machine learning model itself. We will use a fine tuned [DistilBERT hugging face transformer model](https://huggingface.co/docs/transformers/main/en/model_doc/distilbert), which is a \"is a small, fast, cheap and light Transformer model trained by distilling BERT base\". For the sake of time, we will use a pretrained model rather than training the model in the workshop. \n",
    "\n",
    "We will then deploy our trained model using the Seldon Deploy SDK and view our running deployments in the Seldon Deploy UI. \n",
    "\n",
    "We will deploy a second Tensorflow model with slightly differing architecture as a Canary model to demonstrate the A/B testing functionality Seldon Deploy provides. This time we will deploy direct from the UI. \n",
    "\n",
    "Then we will begin to add the advanced monitoring that Seldon Alibi is famed for. \n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "Firstly, we will install and import the relevant packages which we will use throughout the exploration, training, and deployment process. Google Colab comes with a number of packages pre-installed, so we only need to install any additional packages we may need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install seldon_deploy_sdk\n",
    "!pip install alibi_detect==0.8.1\n",
    "!pip install datasets\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datasets\n",
    "import nltk\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "from transformers import AutoTokenizer, DefaultDataCollator, TFAutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seldon_deploy_sdk import Configuration, ApiClient, SeldonDeploymentsApi, ModelMetadataServiceApi, DriftDetectorApi, BatchJobsApi, BatchJobDefinition\n",
    "from seldon_deploy_sdk.auth import OIDCAuthenticator\n",
    "\n",
    "from alibi_detect.cd import KSDrift\n",
    "from alibi_detect.utils.saving import save_detector, load_detector\n",
    "\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data\n",
    "\n",
    "The reviews data is held in a Google Storage bucket. We can download the data using the gsutil tool, which enables us to access Google Cloud storage from the command line. We then load the data into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://kelly-seldon/nlp-ratings/review_data.csv review_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"review_data.csv\", delimiter=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can drop all columns that we don't need to just leave us with ```rating``` and ```review```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['product', 'user_id', 'date_created'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's check for any missing data in our DataFrame and drop rows where the review is missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_NaN = df.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = df[row_has_NaN]\n",
    "print(rows_with_NaN.head(), \"\\n\\n\", \"Number of rows with missing values:\", len(rows_with_NaN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(rows_with_NaN.index)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then ensure that our reviews and ratings columns are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].astype(str)\n",
    "df['rating'] = df['rating'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can map our string rating categories to integers, which will be the output labels for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mapping = {\n",
    "    '1.0': 0,\n",
    "    '1.5': 1,\n",
    "    '2.0': 2,\n",
    "    '2.5': 3,\n",
    "    '3.0': 4,\n",
    "    '3.5': 5,\n",
    "    '4.0': 6, \n",
    "    '4.5': 7,\n",
    "    '5.0': 8\n",
    "}\n",
    "\n",
    "df['label'] = df['rating'].apply(lambda x: rating_mapping[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then drop the rating column to leave us with ```review``` and ```label```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"rating\", axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at some of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a clear need for some text preprocessing of the reviews. \n",
    "\n",
    "We will carry out the following preprocessing steps:\n",
    "\n",
    "- Removing punctuation\n",
    "- Lowercasing\n",
    "- Removing stopwords\n",
    "- Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can remove all punctuation, using the string python library, which contains punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "#storing the puntuation free text\n",
    "df_proc['processed_review']= df_proc['review'].apply(lambda x:remove_punctuation(x))\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can ensure all text is lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc['processed_review']= df_proc['processed_review'].apply(lambda x: x.lower())\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can remove stopwords that don't add any predictive power. The NLTK library consists of a list of words that are considered stopwords for the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "#Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc['processed_review']= df_proc['processed_review'].apply(lambda x:remove_stopwords(x))\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can carry out Lemmatisation to stem the words but ensure they maintain their meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Defining the object for Lemmatisation\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    lemm_text = ' '. join([wordnet_lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return lemm_text\n",
    "\n",
    "df_proc['processed_review']=df_proc['processed_review'].apply(lambda x:lemmatizer(x))\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc.drop(columns=\"review\", inplace=True, axis=1)\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the transformer model\n",
    "\n",
    "Now we will run through the steps to train a hugging face Distilbert transformer using tensorflow. As mentioned previously, we won't actually train the model here, this has been done prior to the workshop, but we will load the trained model into the notebook so we can evaluate it here.\n",
    "\n",
    "First we split the data into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_proc, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we convert to hugging face Datasets for ease in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.Dataset.from_pandas(train, preserve_index=False)\n",
    "test_ds = datasets.Dataset.from_pandas(test, preserve_index=False)\n",
    "comp_ds = datasets.DatasetDict({\"train\":train_ds,\"test\":test_ds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we tokenize the text using a pretrained tokenizer. We need to first instantiate the Distilbert tokenizer class of the library from a pre-trained model vocabulary. Then we create a preprocessing function to tokenize text, truncate sequences to be no longer than DistilBERT’s maximum input length, and pad the text to maximum length accepted by the model, so all inputs are a uniform length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(df):\n",
    "    return tokenizer(df[\"processed_review\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the hugging face Datasets map function to apply the preprocessing function over the entire dataset. We can speed up the map function by setting ```batched=True``` to process multiple elements of the dataset at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_revs = comp_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we initialise a simple data collator creates batches of examples and returns tensors of the correct type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fine-tune a model in TensorFlow, we then convert our train and test datasets to the tf.data.Dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = tokenized_revs[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "tf_test_set = tokenized_revs[\"test\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load DistilBERT with ```TFAutoModelForSequenceClassification```, along with setting the number of expected labels, which in our case is 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run ```model.summary()``` to see the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first layer is the pretrained distilbert layer, so we can set ```trainable``` to ```False``` to save time during model training as we don't need to retrain this layer.\n",
    "\n",
    "Here we also set up an optimizer function, learning rate schedule and loss and accuracy metrics to monitor during training. We then compile the model to configure it for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we call ```fit``` to fine-tune the model, using 5 epochs for training.\n",
    "\n",
    "We will not run this and instead we will load a pre-trained model from a Google Storage bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```model.fit(tf_train_set, validation_data=tf_test_set, epochs=5)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "We can load in the pre-trained model for evaluation purposes.\n",
    "\n",
    "The model is stored in the ```kelly-seldon``` Google Storage bucket at the path ```nlp-ratings/model/1```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"1\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client.create_anonymous_client()\n",
    "bucket = client.bucket('kelly-seldon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(bucket):\n",
    "    blobs = bucket.list_blobs(prefix=\"nlp-ratings/model/1/\")\n",
    "    for blob in blobs:\n",
    "        filename = blob.name.split('/')[-1]\n",
    "        blob.download_to_filename(\"1/\" + filename)\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(\"1\", num_labels=9)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call ```model.summary()``` again to double check the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compile the model again after loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a batch of the test data to save time in the workshop. Usually we would use the whole test set to evaluate the model. The test set is actually passed as a validation set during the model training, so we can see validation loss and accuracy there also, but seeing as we aren't training the model in the workshop, we evaluate the model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = test[:200]\n",
    "test_batch_ds = datasets.Dataset.from_pandas(test_batch, preserve_index=False)\n",
    "tokenized_revs_batch = test_batch_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "test_tf = tokenized_revs_batch.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Long computation in this cell!** ~ 3 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_tf)\n",
    "\n",
    "print(\"Model accuracy: {:2.2%}\".format(accuracy))\n",
    "print(\"Model loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, the accuracy is fairly low. If we look more closely, we see that it classifies almost all reviews as ```8```, translating to a rating of ```5.0```. If we then go back and look at the training set we see that it is very heavily skewed towards a rating of 5.0. We did go back and compute class weights and pass these during model training, however this didn't improve the model performance. This would require a lot more EDA and retraining until we achieved more success with classifying the other ratings, however for now we will move on to model deployment and monitoring to see Seldon's capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the previous sections the reviews are pre-processed using a variety of techniques. In order to account for this we have 2 options for how to account for the pre-processing logic in production:\n",
    "\n",
    "1. **Custom Model:** Incorporate the pre-processing directly in the predict method of a custom model. This provides simplicity when creating the deployment as there is only a single code base to worry about and a single component to be deployed.\n",
    "2. **Input Transformer:** Make use of a separate container to perform all of the input transformation and then pass the vectors to the model for prediction. The schematic below outlines how this would work.\n",
    "\n",
    "```\n",
    "            ________________________________________\n",
    "            |            SeldonDeployment          |\n",
    "            |                                      |\n",
    "Request -->  Input transformer   -->     Model    -->  Response\n",
    "            |  (Pre-processing)          (SKLearn) |\n",
    "            |                                      |\n",
    "            ________________________________________\n",
    "```\n",
    "         \n",
    "The use of an input transformer allows us to separate the pre-processing logic from the prediction logic. This means we can leverage the pre-packaged Tensorflow server provided by Seldon to serve our model, and each of the components can be upgraded independently of one another. However, it does introduce additional complexity in the deployment which is generated, and how that then interacts with advanced monitoring components such as outlier and drift detectors. \n",
    "\n",
    "This workshop will focus on the generation of a **custom model for this case**, therefore we need to define an `__init__` and `predict` method which shall load and perform inference respectively in our new deployment. \n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up \n",
    "\n",
    "We then define our Seldon custom model. The component parts required to build the custom model are outlined below. Each of the files play a key part in building the eventual Seldon docker container.\n",
    "\n",
    "---\n",
    "\n",
    "### ReviewRatings.py\n",
    "\n",
    "\n",
    "This is the critical file as it contains the logic associated with the deployment wrapped as part of a class by the same name as the Python file.\n",
    "\n",
    "A key thing to note about the way this has been structured is that we have focused on making this deployment reusable. The ```__init__``` method accepts a custom predictor parameter - the path to the saved model (```model_path```).\n",
    "\n",
    "The advantage of this is that it allows us to upgrade the model without having to re-build the container image. Additionally, if the logic was more general it could be used to accept a wider variety of objects for greater reusability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, DefaultDataCollator, TFAutoModelForSequenceClassification\n",
    "from google.cloud import storage\n",
    "import logging\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"1\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "nltk.download(\"stopwords\", download_dir=\"./nltk\")\n",
    "nltk.download(\"wordnet\", download_dir=\"./nltk\")\n",
    "nltk.download(\"omw-1.4\", download_dir=\"./nltk\")\n",
    "nltk.data.path.append(\"./nltk\")\n",
    "# Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ReviewRatings(object):\n",
    "    def __init__(self, model_path):\n",
    "        logger.info(\"Connecting to GCS\")\n",
    "        self.client = storage.Client.create_anonymous_client()\n",
    "        self.bucket = self.client.bucket('kelly-seldon')\n",
    "\n",
    "        logger.info(f\"Model name: {model_path}\")\n",
    "        self.model = None\n",
    "        self.prefix = model_path\n",
    "        self.local_dir = \"1/\"\n",
    "\n",
    "        self.wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        logger.info(\"Loading tokenizer and data collator\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "        self.ready = False\n",
    "\n",
    "    def load_model(self):\n",
    "        logger.info(\"Getting model artifact from GCS\")\n",
    "        blobs = self.bucket.list_blobs(prefix=self.prefix)\n",
    "        for blob in blobs:\n",
    "            filename = blob.name.split('/')[-1]\n",
    "            blob.download_to_filename(self.local_dir + filename)\n",
    "        logger.info(\"Loading model\")\n",
    "        self.model = TFAutoModelForSequenceClassification.from_pretrained(\"1\", num_labels=9)\n",
    "        logger.info(f\"{self.model.summary}\")\n",
    "\n",
    "    def preprocess_text(self, text, feature_names):\n",
    "        logger.info(\"Preprocessing text\")\n",
    "        logger.info(f\"Incoming text: {text}\")\n",
    "        text_list = text[0]\n",
    "        dict_text = {\"review\": text_list}\n",
    "        df = pd.DataFrame(data=dict_text)\n",
    "        logger.info(f\"Dataframe created: {df}\")\n",
    "        logger.info(\"Removing punctuation\")\n",
    "        df['review'] = df['review'].apply(lambda x: self.remove_punctuation(x))\n",
    "        logger.info(\"Lowercase all characters\")\n",
    "        df['review'] = df['review'].apply(lambda x: x.lower())\n",
    "        logger.info(\"Removing stopwords\")\n",
    "        df['review'] = df['review'].apply(lambda x: self.remove_stopwords(x))\n",
    "        logger.info(\"Carrying out lemmatization\")\n",
    "        df['review'] = df['review'].apply(lambda x: self.lemmatizer(x))\n",
    "\n",
    "        len_df = len(df)\n",
    "        logger.info(f\"{len(df)}\")\n",
    "\n",
    "        dataset = datasets.Dataset.from_pandas(df, preserve_index=False)\n",
    "        logger.info(f\"Dataset created: {dataset}\")\n",
    "\n",
    "        tokenized_revs = dataset.map(self.tokenize, batched=True)\n",
    "        logger.info(f\"Tokenized reviews: {tokenized_revs}\")\n",
    "\n",
    "        logger.info(\"Converting tokenized reviews to tf dataset\")\n",
    "        tf_inf = tokenized_revs.to_tf_dataset(\n",
    "            columns=[\"attention_mask\", \"input_ids\"],\n",
    "            label_cols=[\"labels\"],\n",
    "            shuffle=True,\n",
    "            batch_size=len_df,\n",
    "            collate_fn=self.data_collator\n",
    "        )\n",
    "        logger.info(f\"TF dataset created: {tf_inf}\")\n",
    "\n",
    "        return tf_inf\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        punctuation_free = \"\".join([i for i in text if i not in string.punctuation])\n",
    "        return punctuation_free\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "        return text\n",
    "\n",
    "    def lemmatizer(self, text):\n",
    "        lemm_text = ' '.join([self.wordnet_lemmatizer.lemmatize(word) for word in text.split()])\n",
    "        return lemm_text\n",
    "\n",
    "    def tokenize(self, ds):\n",
    "        return self.tokenizer(ds[\"review\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    def process_output(self, preds):\n",
    "        logger.info(\"Processing model predictions\")\n",
    "        rating_preds = []\n",
    "        for i in preds[\"logits\"]:\n",
    "            rating_preds.append(np.argmax(i, axis=0))\n",
    "\n",
    "        logger.info(\"Create output array for predictions\")\n",
    "        rating_preds = np.array(rating_preds)\n",
    "\n",
    "        return rating_preds\n",
    "\n",
    "    def process_whole(self, text):\n",
    "        tf_inf = self.preprocess_text(text, feature_names=None)\n",
    "        logger.info(\"Predictions ready to be made\")\n",
    "        preds = self.model.predict(tf_inf)\n",
    "        logger.info(f\"Prediction type: {type(preds)}\")\n",
    "        logger.info(f\"Predictions: {preds}\")\n",
    "        preds_proc = self.process_output(preds)\n",
    "        logger.info(f\"Processed predictions: {preds_proc}, Processed predictions type: {type(preds_proc)}\")\n",
    "\n",
    "        return preds_proc\n",
    "\n",
    "    def predict(self, text, names=[], meta=[]):\n",
    "        try:\n",
    "            if not self.ready:\n",
    "                self.load_model()\n",
    "                logger.info(\"Model successfully loaded\")\n",
    "                self.ready = True\n",
    "                logger.info(f\"{self.model.summary}\")\n",
    "                pred_proc = self.process_whole(text)\n",
    "            else:\n",
    "                pred_proc = self.process_whole(text)\n",
    "\n",
    "            return pred_proc\n",
    "\n",
    "        except Exception as ex:\n",
    "            logging.exception(f\"Failed during predict: {ex}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Locally\n",
    "\n",
    "In order to ensure that we have gotten the `ReviewRatings.py` working correctly we can use the `seldon_core` Python package to run our model locally and test the endpoint. \n",
    "\n",
    "```\n",
    "seldon-core-microservice ReviewRatings --service-type MODEL\n",
    "                                        --parameters='[{ \n",
    "                                                        \"name\": \"model_path\",\n",
    "                                                        \"value\": \"nlp-ratings/model/1/\",\n",
    "                                                        \"type\": \"STRING\"\n",
    "                                                        }]'\n",
    "```\n",
    "\n",
    "This endpoint can then be tested by posting cURL commands to the local endpoint: \n",
    "\n",
    "```\n",
    "curl -H 'Content-Type: application/json' -d '{\"data\": {\"ndarray\": [\"I love the product\"]}}' http://localhost:9000/api/v1.0/predictions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seldon then provides tools to build your reusable container image in two different ways:\n",
    "\n",
    "1. Using ```s2i``` technology\n",
    "2. Write a ```Dockerfile``` if you need more control. \n",
    "\n",
    "In this case, we will create a ```Dockerfile```:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "FROM python:3.8-slim\n",
    "WORKDIR /app\n",
    "\n",
    "# Install python packages\n",
    "COPY requirements.txt requirements.txt\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# Copy source code\n",
    "COPY . .\n",
    "\n",
    "# Port for GRPC\n",
    "EXPOSE 5000\n",
    "# Port for REST\n",
    "EXPOSE 9000\n",
    "\n",
    "# Seldon runs as user 8888 thus change file permissions as such\n",
    "RUN mkdir /.cache\n",
    "RUN chown -R 8888 /.cache\n",
    "RUN chown -R 8888 /app\n",
    "\n",
    "# Define environment variables\n",
    "ENV MODEL_NAME ReviewRatings\n",
    "ENV PERSISTENCE 0\n",
    "ENV SERVICE_TYPE MODEL\n",
    "\n",
    "CMD exec seldon-core-microservice $MODEL_NAME --service-type $SERVICE_TYPE\n",
    "```\n",
    "\n",
    "Note that in order for the Seldon base image to correctly convert your source code to an image it requires certain environment variables. In this case it is only 3 variables:\n",
    "* `MODEL_NAME`: The model name matches the name of the Python file and class which is created. \n",
    "* `SERVICE_TYPE`: Seldon allows you to create many different components each specialised for a different purpose e.g. `TRANSFORMER` for performing pre or post-processing steps. \n",
    "* `PERSISTENCE`: In some cases you would like to save the state of your deployments to Redis e.g. when scaling up multi-armed bandits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have our ```requirements.txt``` file, which contains a list of Python packages which the deployment requires to run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "datasets == 2.2.2\n",
    "numpy == 1.21.6\n",
    "pandas == 1.3.5\n",
    "tensorflow == 2.7.3\n",
    "transformers == 4.20.0\n",
    "seldon_core\n",
    "google-cloud-storage\n",
    "nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will use my pre-built container image for speed and simplicity, which we can now deploy using the SDK. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the model using the SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now deploy your model to the dedicated Seldon Deploy cluster which we have configured for this workshop. To do so you will interact with the Seldon Deploy SDK and deploy your model using that.\n",
    "\n",
    "First, setting up the configuration and authentication required to access the cluster. Make sure to fill in the `SD_IP` variable to be the same as the cluster you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_IP = \"XXXXXXXX\"\n",
    "\n",
    "config = Configuration()\n",
    "config.host = f\"http://{SD_IP}/seldon-deploy/api/v1alpha1\"\n",
    "config.oidc_client_id = \"sd-api\"\n",
    "config.oidc_server = f\"http://{SD_IP}/auth/realms/deploy-realm\"\n",
    "config.oidc_client_secret = \"sd-api-secret\"\n",
    "config.auth_method = \"client_credentials\"\n",
    "\n",
    "def auth():\n",
    "    auth = OIDCAuthenticator(config)\n",
    "    config.id_token = auth.authenticate()\n",
    "    api_client = ApiClient(configuration=config, authenticator=auth)\n",
    "    return api_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have configured the IP correctly as well as setup your authentication function you can describe the deployment you would like to create. \n",
    "\n",
    "You will need to fill in the `YOUR_NAME` variable. This MUST be lower case as it will be used for the `DEPLOYMENT_NAME` variable later on.\n",
    "\n",
    "The `MODEL_NAME` and `MODEL_PATH` variables have been prefilled for you as we are using a pretrained model and a pre-built container image for the sake of saving time in the workshop. \n",
    "\n",
    "The rest of the `mldeployment` description has been completed for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST BE ALL LOWERCASE WITH NO UNDERSCORES\n",
    "YOUR_NAME = YOUR_NAME\n",
    "\n",
    "DEPLOYMENT_NAME = f\"{YOUR_NAME}-prr\"\n",
    "CONTAINER_NAME = f\"tomfarrand/review-ratings:0.3\"\n",
    "\n",
    "NAMESPACE = \"seldon-gitops\"\n",
    "\n",
    "CPU_REQUESTS = \"1\"\n",
    "MEMORY_REQUESTS = \"2Gi\"\n",
    "\n",
    "CPU_LIMITS = \"1\"\n",
    "MEMORY_LIMITS = \"2Gi\"\n",
    "\n",
    "MODEL_PATH = \"nlp-ratings/model/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mldeployment = {\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"labels\": {\n",
    "            \"fluentd\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"spec\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"annotations\": {\n",
    "            \"seldon.io/engine-seldon-log-messages-externally\": \"true\"\n",
    "        },\n",
    "        \"protocol\": \"seldon\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [\n",
    "                    {\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                                    \"image\": CONTAINER_NAME,\n",
    "                                    \"resources\": {\n",
    "                                        \"requests\": {\n",
    "                                            \"cpu\": CPU_REQUESTS,\n",
    "                                            \"memory\": MEMORY_REQUESTS\n",
    "                                        },\n",
    "                                        \"limits\": {\n",
    "                                            \"cpu\": CPU_LIMITS,\n",
    "                                            \"memory\": MEMORY_LIMITS\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"name\": \"default\",\n",
    "                \"replicas\": 1,\n",
    "                \"traffic\": 100,\n",
    "                \"graph\": {\n",
    "                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                    \"parameters\": [\n",
    "                        {\n",
    "                            \"name\":\"model_path\",\n",
    "                            \"value\":MODEL_PATH,\n",
    "                            \"type\":\"STRING\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"children\": [],\n",
    "                    \"logger\": {\n",
    "                        \"mode\": \"all\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"status\": {}\n",
    "}\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now invoke the SeldonDeploymentsApi and create a new Seldon Deployment.\n",
    "\n",
    "Time for you to get your hands dirty. You will use the Seldon Deploy SDK to create a new Seldon deployment. You can find the reference documentation [here](https://github.com/SeldonIO/seldon-deploy-sdk/blob/master/python/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the Seldon Deploy cluster and view your freshly created deployment here:\n",
    "\n",
    "Again, remember to replace the XXXXX with your cluster IP.\n",
    "\n",
    "\n",
    "* URL: http://XXXXX/seldon-deploy/\n",
    "* Username: admin@seldon.io\n",
    "* Password: 12341234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding metadata and prediction schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seldon Deploy has a model catalog where all deployed models are automatically registered. The model catalog can store custom metadata as well as prediction schemas for your models.\n",
    "\n",
    "Metadata promotes lineage from across different machine learning systems, aids knowledge transfer between teams, and allows for faster deployment. Meanwhile, prediction schemas allow Seldon Deploy to automatically profile tabular data into histograms, allowing for filtering on features to explore trends.\n",
    "\n",
    "In order to effectively construct a prediction schema Seldon has the ML Prediction Schema project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_schema = {\n",
    "  \"requests\": [\n",
    "    {\n",
    "      \"name\": \"Review\",\n",
    "      \"type\": \"TEXT\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"nCategories\": \"0\",\n",
    "      \"categoryMap\": {},\n",
    "      \"schema\": [],\n",
    "      \"shape\": []\n",
    "    }\n",
    "  ],\n",
    "  \"responses\": [\n",
    "    {\n",
    "      \"name\": \"Rating\",\n",
    "      \"type\": \"CATEGORICAL\",\n",
    "      \"dataType\": \"INT\",\n",
    "      \"nCategories\": \"9\",\n",
    "      \"categoryMap\": {\n",
    "        \"0\": \"1.0\",\n",
    "        \"1\": \"1.5\",\n",
    "        \"2\": \"2.0\",\n",
    "        \"3\": \"2.5\",\n",
    "        \"4\": \"3.0\",\n",
    "        \"5\": \"3.5\",\n",
    "        \"6\": \"4.0\",\n",
    "        \"7\": \"4.5\",\n",
    "        \"8\": \"5.0\"\n",
    "      },\n",
    "      \"schema\": [],\n",
    "      \"shape\": []\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You then add the prediction schema to the wider model catalog metadata. This includes information such as the model storage location, the name, who authored the model etc. The metadata tags and metrics which can be associated with a model are freeform and can therefore be determined based upon the use case which is being developed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catalog_metadata = {\n",
    "      \"URI\": CONTAINER_NAME,\n",
    "      \"name\": f\"{DEPLOYMENT_NAME}-model\",\n",
    "      \"version\": \"v1.0\",\n",
    "      \"artifactType\": \"CUSTOM\",\n",
    "      \"taskType\": \"Product review rating classification\",\n",
    "      \"tags\": {\n",
    "        \"auto_created\": \"true\",\n",
    "        \"author\": f\"{YOUR_NAME}\"\n",
    "      },\n",
    "      \"metrics\": {\n",
    "          \"accuracy\": f\"{accuracy}\",\n",
    "          \"loss\": f\"{loss}\"\n",
    "      },\n",
    "      \"project\": \"default\",\n",
    "      \"prediction_schema\": prediction_schema\n",
    "    }\n",
    "\n",
    "model_catalog_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using the metadata API you can add this to the model which you have just created in Seldon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_api = ModelMetadataServiceApi(auth())\n",
    "metadata_api.model_metadata_service_update_model_metadata(model_catalog_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then list the metadata via the API, or view it in the UI, to confirm that it has been successfully added to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_response = metadata_api.model_metadata_service_list_model_metadata(uri=CONTAINER_NAME)\n",
    "metadata_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can have a go at sending some requests to your model using the 'Predict' tab in the UI. \n",
    "\n",
    "An example of a good review that we would expect to correspond to a higher rating.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"ndarray\": [\"_product_ is excellent! I love it, it's great!\"]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "And an example of a negative review that we would expect to correspond to a lower rating.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"ndarray\": [\"_product_ was terrible, I would not use it again, it was awful!\"]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B testing - Deploying a Canary Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seldon supports a number of advanced deployment patterns, including Multi-armed bandits, A/B testing, Canary deployments and Shadow deployments. \n",
    "\n",
    "Here, we will deploy a second hugging face transformer model as a Canary Deployment and we will direct 30% of traffic to this model. \n",
    "\n",
    "Again to save time during the workshop, we will use a pre-trained model. This model is almost identical to the previously deployed model - I slightly increased the learning rate and added an extra epoch to change it slightly:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=8e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")\n",
    "\n",
    "model.fit(tf_train_set, validation_data=tf_test_set, epochs=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we can take advantage of the reusable nature of the custom container images as we can use the same custom container image that we saw earlier and just pass a different value to the ```model_path``` predictor parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deploy our Canary model using the Deployment Wizard on the UI. \n",
    "\n",
    "We need to set the following field values:\n",
    "\n",
    "**'Add a Canary'** tab:\n",
    "\n",
    "* Runtime - \"Custom\"\n",
    "* Docker Image - `tomfarrand/review-ratings:0.3`\n",
    "* Canary Traffic Percentage - 30%\n",
    "\n",
    "**'Predictor Parameters'** tab:\n",
    "\n",
    "Use the light green '+' to add a new predictor parameter:\n",
    "\n",
    "- Name - `model_path`\n",
    "- Value - `nlp-ratings/canary/1/`\n",
    "\n",
    "**'Resource Limits'** tab:\n",
    "\n",
    "- Ensure all CPU fields are set to 1.0 and all memory fields are set to 2Gi.\n",
    "\n",
    "Now you can click through the remaining tabs and launch the updated Seldon Deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our canary model is available, we can make predictions and then view live requests and resource monitoring on the \"Dashboard\" tab in the Deployment UI for both models running in production. \n",
    "\n",
    "We will assume that this model has been running in production for some time and it is performing better than our default model. \n",
    "\n",
    "We can then finally go ahead and promote the canary model to be the default model in the deployment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drift Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although powerful, modern machine learning models can be sensitive. Seemingly subtle changes in a data distribution can destroy the performance of otherwise state-of-the art models, which can be especially problematic when ML models are deployed in production. Typically, ML models are tested on held out data in order to estimate their future performance. Crucially, this assumes that the process underlying the input data `X` and output data `Y` remains constant.\n",
    "\n",
    "Drift can be classified into the following types:\n",
    "* **Covariate drift**: Also referred to as input drift, this occurs when the distribution of the input data has shifted `P(X) != Pref(X)`, whilst `P(Y|X) = Pref(Y|X)`. This may result in the model giving unreliable predictions.\n",
    "\n",
    "* **Prior drift**: Also referred to as label drift, this occurs when the distribution of the outputs has shifted `P(Y) != Pref(Y)`, whilst `P(X|Y) = Pref(X|Y)`. This can affect the model’s decision boundary, as well as the model’s performance metrics.\n",
    "\n",
    "* **Concept drift**: This occurs when the process generating `Y` from `X` has changed, such that `P(Y|X) != Pref(Y|X)`. It is possible that the model might no longer give a suitable approximation of the true process.\n",
    "\n",
    "-----------------\n",
    "\n",
    "In this example you will use the Maximum Mean Discrepancy method. Covariate or input drift detection relies on creating a distance measure between two distributions; a reference distribution and a new distribution. The MMD drift detector is no different; the mean embeddings of your features are used to generate the distributions and then the distance between them is measured. The training data is used to calculate the reference distribution, while the new distribution comes from your inference data.\n",
    "\n",
    "\n",
    "We will use part of the training set as our reference distribution. Creating our drift detector is then as simple as writing a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_ref = train[\"processed_review\"][:1000].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alibi Detect comes with a range of transformers out of the box, these can be readily leveraged to generate embeddings from the text which is passed to the model. In this case we make use of a `distilBERT` model. \n",
    "\n",
    "Crucially, the pre-processing which we perform when feeding data to our drift detector does not necessarily have to match the pre-processing being used by the model. This means that the embedding method which generates the best results for the model and the drift detector can be controlled independently of one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.models.tensorflow import TransformerEmbedding\n",
    "\n",
    "emb_type = 'hidden_state'\n",
    "n_layers = 1\n",
    "layers = [-_ for _ in range(1, n_layers + 1)]\n",
    "\n",
    "embedding = TransformerEmbedding(\"distilbert-base-uncased\", emb_type, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(list(x_ref[0][:5]), padding=\"max_length\", return_tensors='tf')\n",
    "x_emb = embedding(tokens)\n",
    "print(x_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding returns a 768 length vector for each of the tokens in the product review. If these were passed directly to the drift detector this would result in an massive computational task due to the sheer number of dimensions.\n",
    "\n",
    "Therefore, the embeddings are then passed through an untrained autoencoder. The autoencoder acts to perform dimensionality reduction, resulting in the 768 length vectors being reduced to 32. This allows for drift detection to be calculated in a near real time setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd.tensorflow import UAE\n",
    "\n",
    "enc_dim = 32\n",
    "shape = (x_emb.shape[1],)\n",
    "\n",
    "uae = UAE(input_layer=embedding, shape=shape, enc_dim=enc_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alibi Detect then allows us to construct a preprocessing function by bringing together each of these different components into a single function which can be readily serialised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "\n",
    "# define preprocessing function\n",
    "preprocess_fn = partial(preprocess_drift, model=uae, tokenizer=tokenizer, max_len=512, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the MMD Drift detector on the reference data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = MMDDrift(x_ref, p_val=.05, preprocess_fn=preprocess_fn, input_shape=(512,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then observe whether drift is flagged on two separate batches of data: \n",
    "- `batch_0` containing the first 100 data points from the reference set. \n",
    "- `batch_1` containing a single example repeated 100 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_0 = x_ref[:100]\n",
    "batch_1 = [x_ref[0]] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cd = cd.predict(batch_0)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds_cd['data']['is_drift']]))\n",
    "print('p-value: {}'.format(preds_cd['data']['p_val']))\n",
    "print('Drift Distance: {}'.format(preds_cd['data']['distance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cd = cd.predict(batch_1)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds_cd['data']['is_drift']]))\n",
    "print('p-value: {}'.format(preds_cd['data']['p_val']))\n",
    "print('Drift Distance: {}'.format(preds_cd['data']['distance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will go ahead and save our drift detectors. We will save them to my public Google Storage bucket, ```kelly-seldon``` for ease in subfolders corresponding to the ```YOUR_NAME``` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_detector(cd, \"reviews-dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp -r reviews-dd gs://kelly-seldon/nlp-ratings/dd/{YOUR_NAME}/reviews-dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Drift Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the drift detector you will use Seldon Deploy's user interface. Simply navigate to your deployment, and select the \"Create\" button for your drift detector.\n",
    "\n",
    "This will bring up a form. Add your ```Detector Name```, the ```Storage URI```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"gs://kelly-seldon/nlp-ratings/dd/{YOUR_NAME}/reviews-dd/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ```Batch Size```:\n",
    "\n",
    "* ```20```\n",
    "\n",
    "and the `Drift Type`:\n",
    "\n",
    "* `Batch`\n",
    "\n",
    "The batch size configuration sets how many data points have to be sent to the endpoint before drift is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Batch Job\n",
    "\n",
    "The simplest way to test that your drift detector and prediction schema are behaving correctly is to kick off a batch job. \n",
    "\n",
    "There is already a pre-prepared batch of data stored in a Minio bucket which Seldon can access, therefore all you have to do is provide the configuration which is outlined below. This shows all of the available parameters which can be changed, but not all are required and are shown for educational purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = BatchJobDefinition(\n",
    "    batch_data_type='data',\n",
    "    batch_gateway_type='seldon',\n",
    "    batch_interval=0.0,\n",
    "    batch_method='predict',\n",
    "    batch_payload_type='ndarray',\n",
    "    batch_retries='3',\n",
    "    batch_size=0,\n",
    "    batch_transport_protocol='rest',\n",
    "    batch_workers='3',\n",
    "    input_data='minio://reviews/batch_examples.txt',\n",
    "    object_store_secret_name='minio-bucket',\n",
    "    output_data='minio://reviews/output_batch_examples.txt',\n",
    "    pvc_size='1Gi'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then pass the above configuration to the batch job API and kick it off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_api = BatchJobsApi(auth())\n",
    "batch_api.create_seldon_deployment_batch_job(DEPLOYMENT_NAME, NAMESPACE, workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "Thank you for sticking it out to the end of the workshop! \n",
    "\n",
    "As a recap you have done the following:\n",
    "\n",
    "1. Explored and preprocessed a set of product review data\n",
    "2. Run through the steps to train a hugging face tensorflow transformer model  \n",
    "3. Deployed that model as a custom model using Seldon\n",
    "4. Added Metadata and Prediction Schema to the model\n",
    "5. Deployed a second model as a canary deployment and promoted that to the default model\n",
    "6. Trained and deployed a drift detector to understand when your data changes. \n",
    "7. Run a batch job to see the drift detector in action\n",
    "\n",
    "Not a bad list. Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
