{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Image Workshop: *Detecting Defects in Steel Strips Using Computer Vision* \n",
    "\n",
    "Within this hands-on workshop you will use a two different convolutional neural networks (CNNs) to classify different types of defects commonly found in steel strips. \n",
    "\n",
    "(And, if you're anything like the author you'll what on Earth defects in steel strips even look like!)\n",
    "\n",
    "The steps which you will carry out are: \n",
    "1. Load the data\n",
    "2. Perform some data exploration and visualisation\n",
    "3. Build a couple of different CNNs and deploy these to Seldon\n",
    "4. Add metadata to your newly created models\n",
    "5. Create a drift detector and once again create this on Seldon\n",
    "\n",
    "The model training code has been adapted from this blog post by `franky` on Medium: [Deep Learning, Computer Vision, and Automated Optical Inspection](https://towardsdatascience.com/deep-learning-computer-vision-and-automated-optical-inspection-774e8ca529d3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we will install and import the relevant packages which we will use throughout the exploration, training, and deployment process. Google Colab comes with a number of packages pre-installed, so we only need to install any additional packages we may need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install seldon_deploy_sdk\n",
    "!pip install alibi-detect==0.8.1\n",
    "!pip install dill\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "# Model Building\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Layer, Reshape, InputLayer, GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Drift Detection\n",
    "# from alibi_detect.cd import MMDDrift\n",
    "# from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "# from alibi_detect.utils.saving import save_detector, load_detector\n",
    "\n",
    "# Seldon Deploy SDK\n",
    "from seldon_deploy_sdk import Configuration, ApiClient, SeldonDeploymentsApi, OutlierDetectorApi, DriftDetectorApi, ModelMetadataServiceApi\n",
    "from seldon_deploy_sdk.auth import OIDCAuthenticator\n",
    "\n",
    "# Logging and Clearing Session\n",
    "tf.keras.backend.clear_session()\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Python dependencies have been installed and imported you can download the training and testing data. This will take approximately 2 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://storage.googleapis.com/deploy-workshops/manufacturing/data/manufacturing-data.zip > manufacturing-data.zip\n",
    "!mkdir data\n",
    "!unzip -o 'manufacturing-data.zip' -d data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Loading the data into memory, as Keras `ImageDataGenerator` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "data_dir='data/train/images/'\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    directory = data_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "data_dir='data/validation/images/'\n",
    "val_ds = train_datagen.flow_from_directory(\n",
    "    directory = data_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 6 classes which you can view below by loading them into the `categories` dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = (train_ds.class_indices)\n",
    "categories = dict((v,k) for k,v in categories.items())\n",
    "categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can readily visualise a sample image to start to gain an understanding of the data you are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = train_ds.next()[0][0]\n",
    "print(example_image.shape)\n",
    "plt.imshow(example_image[:,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above; the images you'll be working with are 3 things: \n",
    "1. Relatively small, only 224 x 224 pixels. \n",
    "2. In colour as they have 3 channels, but appear greyscale. \n",
    "3. Pretty boring to look at!\n",
    "\n",
    "The image below shows a wider variety of the types of image which are available within the dataset. \n",
    "\n",
    "![steel photo examples](https://raw.githubusercontent.com/SeldonIO/deploy-workshops/master/manufacturing/assets/steel_images.jpeg \"Title\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Models\n",
    "\n",
    "Now that the data is loaded in and you have had the chance to explore and get to grips with it, you can turn your attention to model building. \n",
    "\n",
    "You will build and work on 2 separate models: \n",
    "1. Training from scratch a simple hand crafted architecture, using 3 convolutional layers. \n",
    "2. Fine tuning an InceptionV3 model which has been pre-trained on the ImageNet dataset. \n",
    "\n",
    "Once these models have been created you are going to deploy them alongside one another as a canary deployment via the Seldon Deploy SDK. \n",
    "\n",
    "Prior to beginning the building efforts create a simple callback which will stop training early if the validation accuracy breaks 90%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy') > 0.90 ):\n",
    "            print(\"\\nReached 90% validation accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True \n",
    "            \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: *Simple CNN*\n",
    "\n",
    "Using Keras it is straightforward to define the CNN architecture, and this should be familiar if you have worked with CNNs before. \n",
    "\n",
    "Your neural network has three convolutional layers, each with 32 channels and a 3\\*3 convolution. \n",
    "\n",
    "Looking at the model summary you can see the network has a total of approximately 11 million parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)), # First Convolution\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'), # Second Convolution\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'), # Third Convolution\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax'),\n",
    "])\n",
    "\n",
    "simple_cnn.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the network is then straightforward using standard methods; `categorical_crossentropy` for the loss function, and `adam` as the optimisation technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_cnn.compile(loss = 'categorical_crossentropy',\n",
    "                   optimizer = 'adam',\n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "simple_cnn_history = simple_cnn.fit(train_ds,\n",
    "                                    batch_size = 32,\n",
    "                                    epochs = 3,\n",
    "                                    validation_data = val_ds,\n",
    "                                    callbacks = [callbacks],\n",
    "                                    verbose = 1,\n",
    "                                    shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watching a neural network train is the modern equivalent of watching paint dry, therefore to speed things up feel free to interrupt training and grab the pre-trained example available below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir simple-cnn/\n",
    "simple_cnn.save('simple-cnn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!gsutil cp -r simple-cnn/ gs://josh-seldon/workshops/manufacturing/pretrained/simple-cnn/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn = load_model(\"simple-cnn/1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a trained neural network you can grab a test image and have your network generate a prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scratches = load_img('data/validation/images/scratches/scratches_241.jpg',\n",
    "                          target_size=(224, 224, 3))\n",
    "\n",
    "test_scratches = img_to_array(test_scratches)\n",
    "test_scratches = test_scratches / 255\n",
    "test_scratches  = test_scratches.reshape((-1,) + test_scratches.shape)\n",
    "\n",
    "simple_preds = simple_cnn.predict(test_scratches)[0]\n",
    "\n",
    "for v, i in enumerate(simple_preds):\n",
    "    print(f\"{categories[v]}: {i:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the model is... **totally** wrong!\n",
    "\n",
    "Even worse than that, it's confidently wrong- being fully convinced that the test scratch image has in fact been rolled in scale. \n",
    "\n",
    "The checkpointed model you're relying on here only acheived a validation accuracy of around 78% so this might be expected.\n",
    "\n",
    "Let's see if this can be improved upon by using the InceptionV3 architecture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: *InceptionV3*\n",
    "\n",
    "For your second model you will make use of the pre-trained InceptionV3 architecture. InceptionV3 is a CNN built for object classification by [researchers at Google in 2015](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf). Back then it held the state of the art crown for a while, however more recently has been overtaken by more modern EfficientNet or Transformer architectures. \n",
    "\n",
    "It has been selected here because it is reasonable to train on a CPU, it gets great results and Keras has a built-in version of the model making it super easy to get going with!\n",
    "\n",
    "The key information to note around how you are preparing the InceptionV3 model is that when loaded you do not include the final layers (`include_top=False`). \n",
    "\n",
    "Three extra layers are then built on top of the InceptionV3 model; a pooling layer (`GlobalAveragePooling2D`), and two fully connected layers (`Dense`).\n",
    "\n",
    "These new layers are glued onto InceptionV3 and compiled using the same evaluation methods as you used with the `simple-cnn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for architecture\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 6\n",
    "conv_size = 32\n",
    "\n",
    "# parameters for training\n",
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "\n",
    "# load InceptionV3 from Keras\n",
    "InceptionV3_model = InceptionV3(include_top=False, input_shape=input_shape)\n",
    "\n",
    "# add custom Layers\n",
    "x = InceptionV3_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "custom_output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# define the input and output of the model\n",
    "inception = Model(inputs=InceptionV3_model.input, outputs=custom_output)\n",
    "        \n",
    "# compile the model\n",
    "inception.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_history = inception.fit(train_ds,\n",
    "                                  batch_size=32,\n",
    "                                  epochs=1,\n",
    "                                  validation_data=val_ds,\n",
    "                                  callbacks=[callbacks],\n",
    "                                  verbose=1, \n",
    "                                  shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watching an even larger neural network train is simply like watching an even larger wall dry, so once more you can take advantage of a pre-trained artefact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir inception/\n",
    "inception.save('inception/')\n",
    "!gsutil cp -r inception/ gs://josh-seldon/workshops/manufacturing/pretrained/inception/1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir inception/\n",
    "!gsutil cp -r gs://josh-seldon/workshops/manufacturing/pretrained/inception/1 inception/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = load_model(\"inception/1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the `simple_cnn` built earlier you can test your `inception` model on the same `test_scratch` image to get an anecdotal feel for how it's going to perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 920ms/step\n",
      "crazing: 0.00\n",
      "inclusion: 0.00\n",
      "patches: 1.00\n",
      "pitted_surface: 0.00\n",
      "rolled-in_scale: 0.00\n",
      "scratches: 0.00\n"
     ]
    }
   ],
   "source": [
    "inception_preds = inception.predict(test_scratches)[0]\n",
    "\n",
    "for v, i in enumerate(inception_preds):\n",
    "    print(f\"{categories[v]}: {i:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hurrah!** \n",
    "\n",
    "This result looks better, and you can also take some reassurance that this pre-trained `inception` model achieved a much more respectable validation accuracy of 94%. \n",
    "\n",
    "Time to start thinking about how you might want to serve your newly created models. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Your Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have trained and saved your model artefacts you can begin to consider how to deploy them with Seldon. \n",
    "\n",
    "This process will involve uploading the relevant artefacts to blob storage, where they can be pulled from at deployment time. (As we will use the pretrained models rather than training in the workshop, the models are already in a google storage bucket, so we don't need to carry out the upload.)\n",
    "\n",
    "You will then configure connection to a Seldon Deploy cluster, and leverage the pre-built Tensorflow Serving runtime to create your deployment. \n",
    "\n",
    "---\n",
    "\n",
    "To begin with, you will push the `simple-cnn` and `inception` models to a Google storage bucket. It's worth noting that Seldon Deploy reads from a wide range of storage back ends and so all of the popular blob storage tools are covered as well. (As we will use the pretrained models rather than training in the workshop, the models are already in a google storage bucket, so we don't need to carry out the upload.).\n",
    "\n",
    "You will create a unique folder with your name. Remember to replace `YOUR NAME` with your name.\n",
    "\n",
    "Tensorflow Serving, similarly to Nvidia's Triton, when pulling model artefacts from a directory expects that there are sub-directories representing the version of the model artefacts. TF Serving can then be configured to serve a given model version. \n",
    "\n",
    "Given that you only have the single version for both of your models currently you will simply save version 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !gsutil cp -r simple-cnn/1/ gs://tom-seldon-examples/workshops/manufacturing/<YOUR NAME>/simple-cnn/\n",
    "# !gsutil cp -r inception/1/ gs://tom-seldon-examples/workshops/manufacturing/<YOUR NAME>/inception/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Triton Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "        \"name\": model_name,\n",
    "        \"platform\": \"tensorflow\",\n",
    "        \"version_policy\": {\"specific\": {\"versions\": [1]}},\n",
    "        \"input\": [],\n",
    "        \"output\": [],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.saved_model.load._WrapperFunction'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m         f\u001b[39m.\u001b[39mwrite(text_format\u001b[39m.\u001b[39mMessageToString(model_config))\n\u001b[1;32m     44\u001b[0m \u001b[39m# Usage\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m create_config(\u001b[39m\"\u001b[39;49m\u001b[39m./simple-cnn\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msimple-cnn\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[53], line 25\u001b[0m, in \u001b[0;36mcreate_config\u001b[0;34m(saved_model_dir, model_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m model_config\u001b[39m.\u001b[39mplatform \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39m# # Set the version policy (optional)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# model_config.version_policy.max_versions = 1\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# model_config.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[39m# Iterate over the inputs in the signature def\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfor\u001b[39;00m input_name, input_tensor_info \u001b[39min\u001b[39;00m signature_def\u001b[39m.\u001b[39;49minputs\u001b[39m.\u001b[39;49mitems():\n\u001b[1;32m     26\u001b[0m     \u001b[39m# Create Triton model input\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     input_config \u001b[39m=\u001b[39m model_config\u001b[39m.\u001b[39minput\u001b[39m.\u001b[39madd()\n\u001b[1;32m     28\u001b[0m     input_config\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m input_name\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tritonclient.utils import triton_to_np_dtype\n",
    "from tritonclient.utils import np_to_triton_dtype\n",
    "from google.protobuf import text_format\n",
    "from tritonclient.grpc.model_config_pb2 import ModelConfig\n",
    "from tensorflow.python.saved_model import saved_model_utils\n",
    "\n",
    "\n",
    "def create_config(saved_model_dir, model_name):\n",
    "    # Load the TensorFlow SavedModel\n",
    "    loaded_model = tf.saved_model.load(saved_model_dir, tags=[tag_constants.SERVING])\n",
    "\n",
    "    # Get the signature def from the loaded model\n",
    "    signature_def = loaded_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "    print(type(signature_def))\n",
    "    # Create Triton model configuration\n",
    "    model_config = ModelConfig()\n",
    "    model_config.name = model_name\n",
    "    model_config.platform = \"tensorflow\"\n",
    "\n",
    "    # # Set the version policy (optional)\n",
    "    # model_config.version_policy.max_versions = 1\n",
    "    # model_config.\n",
    "\n",
    "    # Iterate over the inputs in the signature def\n",
    "    for input_name, input_tensor_info in signature_def.inputs.items():\n",
    "        # Create Triton model input\n",
    "        input_config = model_config.input.add()\n",
    "        input_config.name = input_name\n",
    "        input_config.data_type = triton_to_np_dtype(input_tensor_info.dtype)\n",
    "        input_config.dims.extend(input_tensor_info.shape)\n",
    "\n",
    "    # Iterate over the outputs in the signature def\n",
    "    for output_name, output_tensor_info in signature_def.outputs.items():\n",
    "        # Create Triton model output\n",
    "        output_config = model_config.output.add()\n",
    "        output_config.name = output_name\n",
    "        output_config.data_type = triton_to_np_dtype(output_tensor_info.dtype)\n",
    "        output_config.dims.extend(output_tensor_info.shape)\n",
    "\n",
    "    # Save the Triton model config to a file\n",
    "    with open(\"config.pbtxt\", \"w\") as f:\n",
    "        f.write(text_format.MessageToString(model_config))\n",
    "\n",
    "# Usage\n",
    "create_config(\"./simple-cnn\", \"simple-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2043 - accuracy: 0.9422 - val_loss: 0.0802 - val_accuracy: 0.9753\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m input_config \u001b[39m=\u001b[39m model_config\u001b[39m.\u001b[39minput\u001b[39m.\u001b[39madd()\n\u001b[1;32m     38\u001b[0m input_config\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 39\u001b[0m input_config\u001b[39m.\u001b[39;49mdata_type \u001b[39m=\u001b[39m triton_to_np_dtype(x_train\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m     40\u001b[0m input_config\u001b[39m.\u001b[39mdims\u001b[39m.\u001b[39mextend(x_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     42\u001b[0m \u001b[39m# Iterate over the outputs in the model\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tritonclient.utils import triton_to_np_dtype\n",
    "from tritonclient.grpc.model_config_pb2 import ModelConfig\n",
    "from google.protobuf import text_format\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28, 28, 1)).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape((-1, 28, 28, 1)).astype(\"float32\") / 255.0\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"trained_model\")\n",
    "\n",
    "# Create Triton model configuration\n",
    "model_config = ModelConfig()\n",
    "model_config.name = \"mnist-model\"\n",
    "model_config.platform = \"tensorflow\"\n",
    "\n",
    "# Set the version policy (optional)\n",
    "# model_config.version_policy.max_versions = 1\n",
    "\n",
    "# Iterate over the inputs in the model\n",
    "input_config = model_config.input.add()\n",
    "input_config.name = \"input\"\n",
    "input_config.data_type = triton_to_np_dtype(x_train.dtype)\n",
    "input_config.dims.extend(x_train[0].shape)\n",
    "\n",
    "# Iterate over the outputs in the model\n",
    "output_config = model_config.output.add()\n",
    "output_config.name = \"output\"\n",
    "output_config.data_type = triton_to_np_dtype(y_train.dtype)\n",
    "output_config.dims.extend(y_train[0].shape)\n",
    "\n",
    "# Save the Triton model config to a file\n",
    "with open(\"config.pbtxt\", \"w\") as f:\n",
    "    f.write(text_format.MessageToString(model_config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Protocol message Specific has no \"version\" field.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m create_config(\u001b[39m\"\u001b[39;49m\u001b[39m./simple-cnn\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msimple-cnn\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[47], line 36\u001b[0m, in \u001b[0;36mcreate_config\u001b[0;34m(saved_model_dir, model_name)\u001b[0m\n\u001b[1;32m     33\u001b[0m model_config\u001b[39m.\u001b[39mplatform \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[39m# Set the version policy (optional)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m model_config\u001b[39m.\u001b[39;49mversion_policy\u001b[39m.\u001b[39;49mspecific\u001b[39m.\u001b[39;49mversion \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[39m# Iterate over the inputs in the signature def\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m input_name, input_tensor_info \u001b[39min\u001b[39;00m signature_def\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     40\u001b[0m     \u001b[39m# Create Triton model input\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Protocol message Specific has no \"version\" field."
     ]
    }
   ],
   "source": [
    "create_config(\"./simple-cnn\", \"simple-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now deploy your models to the dedicated Seldon Deploy cluster which has been configured for this workshop. To do so you will interact with the Seldon Deploy SDK and deploy your model using that.\n",
    "\n",
    "First, setting up the configuration and authentication required to access the cluster. Don't forget to update the `SD_IP` variable to your cluster IP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_IP = \"35.243.251.120\"\n",
    "config = Configuration()\n",
    "config.host = f\"https://{SD_IP}/seldon-deploy/api/v1alpha1\"\n",
    "config.oidc_client_id = \"sd-api\"\n",
    "config.oidc_server = f\"https://{SD_IP}/auth/realms/deploy-realm\"\n",
    "config.oidc_client_secret = \"sd-api-secret\"\n",
    "config.auth_method = \"client_credentials\"\n",
    "config.verify_ssl = False\n",
    "\n",
    "def auth():\n",
    "    auth = OIDCAuthenticator(config)\n",
    "    config.id_token = auth.authenticate()\n",
    "    api_client = ApiClient(configuration=config, authenticator=auth)\n",
    "    return api_client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have configured the IP correctly as well as setup the authentication function you can describe the deployment you would like to create. \n",
    "\n",
    "As you have uncovered earlier the `simple-cnn` is not great, and the `inception` model improves dramatically on that performance. This has been demonstrated on your validation data, but neither model has seen any live data. \n",
    "\n",
    "In this scenario you may wish to test both models on the live data, to achieve this Seldon Deploy provides you with two options; a shadow deployment or a canary deployment. \n",
    "\n",
    "These techniques are usually applied to the rollout or upgrade of a new model version. A shadow deployment deploys two models behind a single endpoint, both of the models receive 100% of the traffic- there is no split. However, only one of the models' responses are returned to users- usually the original model you are upgrading. The others responses (new version) are simply logged to Elasticsearch where you can see how it responded compared to the original model. This allows you to roll out new versions of a model and test them on live data, without the risk of poor performance impacting user experience. \n",
    "\n",
    "The other option is a canary deployment; this involves a traffic split between the two models behind a single endpoint. The percentage split is determined by you, and allows you to control how much of the live data goes to each of the models. New versions of models will typically be sent a smaller percentage of traffic (10% or 20%) to validate they are behaving as expected before they are rolled out more fully.\n",
    "\n",
    "In this example you will create a canary deployment with a 70/30 split between the `inception` model and `simple-cnn` respectively. \n",
    "\n",
    "---\n",
    "\n",
    "The [Seldon Deploy SDK](https://github.com/SeldonIO/seldon-deploy-sdk) offers two approaches to creating deployments: \n",
    "1. Working directly with dictionaries, which are equivalent to the underlying Kubernetes manifests. \n",
    "2. Using the higher level Python classes as abstractions. \n",
    "\n",
    "In this example you will use the more direct approach of working with the dictionaries. While this requires some more configuration it does create the opportunity to make reusable templates which are custom to your needs and can be readily shared and understood by others. \n",
    "\n",
    "You will start by defining some variables for the deployment which will be passed to the `mldeployment` manifest object in the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_NAME = \"jman\"\n",
    "DEPLOYMENT_NAME = f\"{YOUR_NAME}-manufacturing\"\n",
    "NAMESPACE = \"seldon-gitops\"\n",
    "\n",
    "MODEL_NAME = \"inception\"\n",
    "MODEL_LOCATION = f\"gs://josh-seldon/workshops/manufacturing/pretrained/simple-cnn/\"\n",
    "\n",
    "CANARY_NAME = \"simple-cnn\"\n",
    "CANARY_LOCATION = f\"gs://josh-seldon/workshops/manufacturing/pretrained/inception/\"\n",
    "\n",
    "CPU_REQUESTS = \"1\"\n",
    "MEMORY_REQUESTS = \"1Gi\"\n",
    "\n",
    "CPU_LIMITS = \"1\"\n",
    "MEMORY_LIMITS = \"1Gi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mldeployment = {\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"namespace\": NAMESPACE\n",
    "    },\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"spec\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"protocol\": \"seldon\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [\n",
    "                    {\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": f\"{CANARY_NAME}\",\n",
    "                                    \"resources\": {\n",
    "                                        \"requests\": {\n",
    "                                            \"cpu\": CPU_REQUESTS,\n",
    "                                            \"memory\": MEMORY_REQUESTS\n",
    "                                        },\n",
    "                                        \"limits\": {\n",
    "                                            \"cpu\": CPU_LIMITS,\n",
    "                                            \"memory\": MEMORY_LIMITS\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"name\": \"default\",\n",
    "                \"replicas\": 1,\n",
    "                \"traffic\": 100,\n",
    "                \"graph\": {\n",
    "                    \"implementation\": \"TENSORFLOW_SERVER\",\n",
    "                    \"modelUri\": CANARY_LOCATION,\n",
    "                    \"name\": f\"{CANARY_NAME}\",\n",
    "                    \"logger\": {\n",
    "                        \"mode\": \"all\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "             ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have specified your `mldeployment` JSON it is a simple API call to create your deployment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'api_version': 'machinelearning.seldon.io/v1',\n",
       " 'kind': 'SeldonDeployment',\n",
       " 'metadata': {'annotations': None,\n",
       "              'cluster_name': None,\n",
       "              'creation_timestamp': None,\n",
       "              'deletion_grace_period_seconds': None,\n",
       "              'deletion_timestamp': None,\n",
       "              'finalizers': None,\n",
       "              'generate_name': None,\n",
       "              'generation': None,\n",
       "              'labels': None,\n",
       "              'managed_fields': None,\n",
       "              'name': 'jman-manufacturing',\n",
       "              'namespace': 'seldon-gitops',\n",
       "              'owner_references': None,\n",
       "              'resource_version': None,\n",
       "              'self_link': None,\n",
       "              'uid': None},\n",
       " 'spec': {'annotations': None,\n",
       "          'name': 'jman-manufacturing',\n",
       "          'oauth_key': None,\n",
       "          'oauth_secret': None,\n",
       "          'predictors': [{'annotations': None,\n",
       "                          'component_specs': [{'hpa_spec': None,\n",
       "                                               'keda_spec': None,\n",
       "                                               'metadata': {'annotations': None,\n",
       "                                                            'cluster_name': None,\n",
       "                                                            'creation_timestamp': '2023-06-19T20:32:49Z',\n",
       "                                                            'deletion_grace_period_seconds': None,\n",
       "                                                            'deletion_timestamp': None,\n",
       "                                                            'finalizers': None,\n",
       "                                                            'generate_name': None,\n",
       "                                                            'generation': None,\n",
       "                                                            'labels': None,\n",
       "                                                            'managed_fields': None,\n",
       "                                                            'name': None,\n",
       "                                                            'namespace': None,\n",
       "                                                            'owner_references': None,\n",
       "                                                            'resource_version': None,\n",
       "                                                            'self_link': None,\n",
       "                                                            'uid': None},\n",
       "                                               'pdb_spec': None,\n",
       "                                               'replicas': None,\n",
       "                                               'spec': {'active_deadline_seconds': None,\n",
       "                                                        'affinity': None,\n",
       "                                                        'automount_service_account_token': None,\n",
       "                                                        'containers': [{'args': None,\n",
       "                                                                        'command': None,\n",
       "                                                                        'env': None,\n",
       "                                                                        'env_from': None,\n",
       "                                                                        'image': None,\n",
       "                                                                        'image_pull_policy': None,\n",
       "                                                                        'lifecycle': None,\n",
       "                                                                        'liveness_probe': None,\n",
       "                                                                        'name': 'inception',\n",
       "                                                                        'ports': None,\n",
       "                                                                        'readiness_probe': None,\n",
       "                                                                        'resources': {'limits': {'cpu': '1',\n",
       "                                                                                                 'memory': '1Gi'},\n",
       "                                                                                      'requests': {'cpu': '1',\n",
       "                                                                                                   'memory': '1Gi'}},\n",
       "                                                                        'security_context': None,\n",
       "                                                                        'startup_probe': None,\n",
       "                                                                        'stdin': None,\n",
       "                                                                        'stdin_once': None,\n",
       "                                                                        'termination_message_path': None,\n",
       "                                                                        'termination_message_policy': None,\n",
       "                                                                        'tty': None,\n",
       "                                                                        'volume_devices': None,\n",
       "                                                                        'volume_mounts': None,\n",
       "                                                                        'working_dir': None}],\n",
       "                                                        'dns_config': None,\n",
       "                                                        'dns_policy': None,\n",
       "                                                        'enable_service_links': None,\n",
       "                                                        'ephemeral_containers': None,\n",
       "                                                        'host_aliases': None,\n",
       "                                                        'host_ipc': None,\n",
       "                                                        'host_network': None,\n",
       "                                                        'host_pid': None,\n",
       "                                                        'hostname': None,\n",
       "                                                        'image_pull_secrets': None,\n",
       "                                                        'init_containers': None,\n",
       "                                                        'node_name': None,\n",
       "                                                        'node_selector': None,\n",
       "                                                        'overhead': None,\n",
       "                                                        'preemption_policy': None,\n",
       "                                                        'priority': None,\n",
       "                                                        'priority_class_name': None,\n",
       "                                                        'readiness_gates': None,\n",
       "                                                        'restart_policy': None,\n",
       "                                                        'runtime_class_name': None,\n",
       "                                                        'scheduler_name': None,\n",
       "                                                        'security_context': None,\n",
       "                                                        'service_account': None,\n",
       "                                                        'service_account_name': None,\n",
       "                                                        'set_hostname_as_fqdn': None,\n",
       "                                                        'share_process_namespace': None,\n",
       "                                                        'subdomain': None,\n",
       "                                                        'termination_grace_period_seconds': None,\n",
       "                                                        'tolerations': None,\n",
       "                                                        'topology_spread_constraints': None,\n",
       "                                                        'volumes': None}}],\n",
       "                          'engine_resources': {'limits': None,\n",
       "                                               'requests': None},\n",
       "                          'explainer': None,\n",
       "                          'graph': {'children': None,\n",
       "                                    'endpoint': None,\n",
       "                                    'env_secret_ref_name': None,\n",
       "                                    'implementation': 'TENSORFLOW_SERVER',\n",
       "                                    'logger': {'mode': 'all', 'url': None},\n",
       "                                    'methods': None,\n",
       "                                    'model_uri': 'gs://josh-seldon/workshops/manufacturing/pretrained/simple-cnn/',\n",
       "                                    'name': 'inception',\n",
       "                                    'parameters': None,\n",
       "                                    'service_account_name': None,\n",
       "                                    'storage_initializer_image': None,\n",
       "                                    'type': None},\n",
       "                          'labels': None,\n",
       "                          'name': 'default',\n",
       "                          'progress_deadline_seconds': None,\n",
       "                          'replicas': 1,\n",
       "                          'shadow': None,\n",
       "                          'ssl': None,\n",
       "                          'svc_orch_spec': {'env': None,\n",
       "                                            'replicas': None,\n",
       "                                            'resources': None},\n",
       "                          'traffic': 70},\n",
       "                         {'annotations': {'seldon.io/canary': 'true'},\n",
       "                          'component_specs': [{'hpa_spec': None,\n",
       "                                               'keda_spec': None,\n",
       "                                               'metadata': {'annotations': None,\n",
       "                                                            'cluster_name': None,\n",
       "                                                            'creation_timestamp': '2023-06-19T20:32:49Z',\n",
       "                                                            'deletion_grace_period_seconds': None,\n",
       "                                                            'deletion_timestamp': None,\n",
       "                                                            'finalizers': None,\n",
       "                                                            'generate_name': None,\n",
       "                                                            'generation': None,\n",
       "                                                            'labels': None,\n",
       "                                                            'managed_fields': None,\n",
       "                                                            'name': None,\n",
       "                                                            'namespace': None,\n",
       "                                                            'owner_references': None,\n",
       "                                                            'resource_version': None,\n",
       "                                                            'self_link': None,\n",
       "                                                            'uid': None},\n",
       "                                               'pdb_spec': None,\n",
       "                                               'replicas': None,\n",
       "                                               'spec': {'active_deadline_seconds': None,\n",
       "                                                        'affinity': None,\n",
       "                                                        'automount_service_account_token': None,\n",
       "                                                        'containers': [{'args': None,\n",
       "                                                                        'command': None,\n",
       "                                                                        'env': None,\n",
       "                                                                        'env_from': None,\n",
       "                                                                        'image': None,\n",
       "                                                                        'image_pull_policy': None,\n",
       "                                                                        'lifecycle': None,\n",
       "                                                                        'liveness_probe': None,\n",
       "                                                                        'name': 'simple-cnn',\n",
       "                                                                        'ports': None,\n",
       "                                                                        'readiness_probe': None,\n",
       "                                                                        'resources': {'limits': {'cpu': '1',\n",
       "                                                                                                 'memory': '1Gi'},\n",
       "                                                                                      'requests': {'cpu': '1',\n",
       "                                                                                                   'memory': '1Gi'}},\n",
       "                                                                        'security_context': None,\n",
       "                                                                        'startup_probe': None,\n",
       "                                                                        'stdin': None,\n",
       "                                                                        'stdin_once': None,\n",
       "                                                                        'termination_message_path': None,\n",
       "                                                                        'termination_message_policy': None,\n",
       "                                                                        'tty': None,\n",
       "                                                                        'volume_devices': None,\n",
       "                                                                        'volume_mounts': None,\n",
       "                                                                        'working_dir': None}],\n",
       "                                                        'dns_config': None,\n",
       "                                                        'dns_policy': None,\n",
       "                                                        'enable_service_links': None,\n",
       "                                                        'ephemeral_containers': None,\n",
       "                                                        'host_aliases': None,\n",
       "                                                        'host_ipc': None,\n",
       "                                                        'host_network': None,\n",
       "                                                        'host_pid': None,\n",
       "                                                        'hostname': None,\n",
       "                                                        'image_pull_secrets': None,\n",
       "                                                        'init_containers': None,\n",
       "                                                        'node_name': None,\n",
       "                                                        'node_selector': None,\n",
       "                                                        'overhead': None,\n",
       "                                                        'preemption_policy': None,\n",
       "                                                        'priority': None,\n",
       "                                                        'priority_class_name': None,\n",
       "                                                        'readiness_gates': None,\n",
       "                                                        'restart_policy': None,\n",
       "                                                        'runtime_class_name': None,\n",
       "                                                        'scheduler_name': None,\n",
       "                                                        'security_context': None,\n",
       "                                                        'service_account': None,\n",
       "                                                        'service_account_name': None,\n",
       "                                                        'set_hostname_as_fqdn': None,\n",
       "                                                        'share_process_namespace': None,\n",
       "                                                        'subdomain': None,\n",
       "                                                        'termination_grace_period_seconds': None,\n",
       "                                                        'tolerations': None,\n",
       "                                                        'topology_spread_constraints': None,\n",
       "                                                        'volumes': None}}],\n",
       "                          'engine_resources': {'limits': None,\n",
       "                                               'requests': None},\n",
       "                          'explainer': None,\n",
       "                          'graph': {'children': None,\n",
       "                                    'endpoint': None,\n",
       "                                    'env_secret_ref_name': None,\n",
       "                                    'implementation': 'TENSORFLOW_SERVER',\n",
       "                                    'logger': {'mode': 'all', 'url': None},\n",
       "                                    'methods': None,\n",
       "                                    'model_uri': 'gs://josh-seldon/workshops/manufacturing/pretrained/inception/',\n",
       "                                    'name': 'simple-cnn',\n",
       "                                    'parameters': None,\n",
       "                                    'service_account_name': None,\n",
       "                                    'storage_initializer_image': None,\n",
       "                                    'type': None},\n",
       "                          'labels': None,\n",
       "                          'name': 'canary',\n",
       "                          'progress_deadline_seconds': None,\n",
       "                          'replicas': 1,\n",
       "                          'shadow': None,\n",
       "                          'ssl': None,\n",
       "                          'svc_orch_spec': {'env': None,\n",
       "                                            'replicas': None,\n",
       "                                            'resources': None},\n",
       "                          'traffic': 30}],\n",
       "          'protocol': 'seldon',\n",
       "          'replicas': None,\n",
       "          'server_type': None,\n",
       "          'transport': None},\n",
       " 'status': {'address': None,\n",
       "            'annotations': None,\n",
       "            'conditions': None,\n",
       "            'deployment_status': None,\n",
       "            'description': None,\n",
       "            'observed_generation': None,\n",
       "            'replicas': None,\n",
       "            'service_status': None,\n",
       "            'state': None}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now test your model endpoint in the UI. To access the workshop cluster use the following details: \n",
    "\n",
    "Don't forget to replace XXXXX in the below URL with your cluster IP.\n",
    "\n",
    "* Seldon Deploy URL: http://XXXXX/seldon-deploy/\n",
    "* Username: admin@seldon.io\n",
    "* Password: 12341234\n",
    "\n",
    "Once you have seen your deployment creating you can save a sample image using the `test-scratches` array you worked with earlier. \n",
    "\n",
    "This `test-scratches.json` can be uploaded directly to the UI to test your model endpoint when it is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldon_sample = {\n",
    "  \"data\": {\n",
    "    \"names\": [\n",
    "    ],\n",
    "    \"ndarray\": test_scratches.tolist()\n",
    "  }\n",
    "}\n",
    "\n",
    "with open('test-scratches.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(seldon_sample, f, ensure_ascii=False, indent=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Model Metadata\n",
    "\n",
    "You have now created 2 new models within a single deployment. Both of these models have been automatically added to the model catalog. The model catalog acts as a centralised repository for metadata associated with models. Models can be easily deployed directly from the catalog, while metadata acts to speed knowledge transfer between teams and to track models across tools.\n",
    "\n",
    "You will now add some metadata to your InceptionV3 model describing the validation accuracy you managed to achieve, and who authored the model- so you can brag to your colleagues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catalog_metadata = {\n",
    "      \"URI\": MODEL_LOCATION,\n",
    "      \"name\": \"InceptionV3\",\n",
    "      \"version\": \"v1.0\",\n",
    "      \"artifactType\": \"TENSORFLOW\",\n",
    "      \"taskType\": \"defect classification\",\n",
    "      \"tags\": {\n",
    "        \"auto_created\": \"true\",\n",
    "        \"author\": f\"{YOUR_NAME}\"\n",
    "      },\n",
    "      \"metrics\": {},\n",
    "      \"creationTime\": \"2022-02-15T15:26:26.630592Z\",\n",
    "      \"project\": \"default\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = ModelMetadataServiceApi(auth())\n",
    "api_response = api_instance.model_metadata_service_update_model_metadata(model_catalog_metadata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing the metadata for your newly updated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_response = api_instance.model_metadata_service_list_model_metadata(uri=MODEL_LOCATION)\n",
    "api_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift Detection\n",
    "\n",
    "The final stage of the deployment process is going to be adding the advanced monitoring capabilities afforded by a drift detector. \n",
    "\n",
    "In this example you will use Alibi Detect to train a custom drift detector which can flag when the underlying input data distribution has shifted. This can inform decisions about re-training or prompt deeper investigation into data/model behaviours. \n",
    "\n",
    "Seldon Deploy also allows you to setup alerts when drift is detected. \n",
    "\n",
    "---\n",
    "\n",
    "In this example you will use the Maximum Mean Discrepancy method. Covariate or input drift detection relies on creating a distance measure between two distributions; a reference distribution and a new distribution. The MMD drift detector is no different; the mean embeddings of your features are used to generate the distributions and then the distance between them is measured. The training data is used to calculate the reference distribution, while the new distribution comes from your inference data.  \n",
    "\n",
    "More technically, a reproducing kernel Hilbert space is used to generate the mean embeddings, by mapping the highly complex feature space within which most machine learning models operate to a linear Euclidean space. A radial basis function kernel is then used to measure the distance between the two embeddings, and the signifiance of the drift is calculated as a p-value using permutation/resampling tests. More details can be found [here](https://docs.seldon.io/projects/alibi-detect/en/v0.10.3/cd/methods/mmddrift.html).\n",
    "\n",
    "Before you dive into creating your own drift detector, you need to generate a reference dataset. In this case you use 5 batches of the training data set, resulting in 160 images. This has been picked for convenience and speed of training in the workshop, and if this was a production case you would likely want to use the entirety of the training set, or a statistically significant segment.\n",
    "\n",
    "Now, creating your reference set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.reset()\n",
    "\n",
    "drift_ref = train_ds.next()[0]\n",
    "\n",
    "for i in range(4):\n",
    "    drift_ref = np.concatenate((drift_ref, train_ds.next()[0]))\n",
    "\n",
    "drift_ref.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high dimensionality of image data you will need perform a pre-processing step to make it computationally feasible to detect drift on incoming batches of images. \n",
    "\n",
    "A great option for this is to use an simple encoding neural network. This will squish images from their original shape of `(224, 224, 3)` to a vector of `32`. From there we can feed the vectors to the drift detector and calculate drift values. \n",
    "\n",
    "This is then used to a generate a `preprocess_fn` which will be fed to your MMD drift detector to convert your images ahead of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder\n",
    "encoding_dim = 32\n",
    "encoder_net = tf.keras.Sequential(\n",
    "  [\n",
    "      InputLayer(input_shape=(224, 224, 3)),\n",
    "      Conv2D(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Flatten(),\n",
    "      Dense(encoding_dim,)\n",
    "  ]\n",
    ")\n",
    "\n",
    "# define preprocessing function\n",
    "preprocess_fn = partial(preprocess_drift, model=encoder_net, batch_size=160)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you can initialise the drift detector; this is as simple as a single line API call specifying the:\n",
    "* Reference data\n",
    "* Computational backend\n",
    "* The p-value below which drift is considered to have occurred\n",
    "* Your preprocessing function\n",
    "* The number of permutations taken to calculate the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise drift detector\n",
    "cd = MMDDrift(drift_ref, backend='tensorflow', p_val=.05, preprocess_fn=preprocess_fn, n_permutations=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your shiny new drift detector has trained you can test it on a new batch of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch = train_ds.next()[0]\n",
    "preds = cd.predict(new_batch, return_p_val=True, return_distance=True)\n",
    "preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can save the drift detector and upload it to Google storage for deployment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'defect-drift'\n",
    "save_detector(cd, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp -r defect-drift gs://tom-seldon-examples/workshops/manufacturing/{YOUR_NAME}/defect-drift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the drift detector you will use Seldon Deploy's user interface. Simply navigate to your deployment, and select the \"Create\" button for your drift detector.\n",
    "\n",
    "This will bring up a form. Add your `Detector Name`, the `Storage URI`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"gs://tom-seldon-examples/workshops/manufacturing/{YOUR_NAME}/defect-drift\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `Batch Size`:\n",
    "\n",
    "20\n",
    "\n",
    "and the `Drift Type`:\n",
    "\n",
    "Batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size configuration sets how many data points have to be sent to the endpoint before drift is calculated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test your drift detector, you can run the same image through your deployed model 20 times. You can see both in the drift detector logs and in the Drift Detection screen within the monitoring tab, that drift has occurred. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('manufacturing-workshop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8be410a4c5d7d538b65aa21c14d5f134415913f02f6768f234dcb4d6d6ec87ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
