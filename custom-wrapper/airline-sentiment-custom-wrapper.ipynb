{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20eec117",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-15T07:48:52.44714Z",
     "iopub.status.busy": "2021-11-15T07:48:52.446721Z",
     "iopub.status.idle": "2021-11-15T07:48:52.478971Z",
     "shell.execute_reply": "2021-11-15T07:48:52.4775Z",
     "shell.execute_reply.started": "2021-11-15T07:48:52.447038Z"
    },
    "papermill": {
     "duration": 0.032152,
     "end_time": "2021-11-15T08:54:16.800827",
     "exception": false,
     "start_time": "2021-11-15T08:54:16.768675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hands-On NLP Workshop: *Detecting Sentiment Using Tweets to US Airlines*\n",
    "\n",
    "Within this hands-on workshop you will analyse tweets from customers of airlines about their performance. These were scraped from Twitter in 2015, and will be categorised in positive, neutral or negative sentiment. \n",
    "  \n",
    "The steps which have been carried out\n",
    "1. Load The Data \n",
    "2. Data Visualization \n",
    "3. Text Preprocessing and Cleaning  \n",
    "4. Handling Imbalance         \n",
    "5. Model Building  \n",
    "\n",
    "The code in this notebook has been adapted from the brilliant work done by [Meisam Raz](https://www.kaggle.com/meisamraz/sentiment-analysis-96-acc-eda-text-preprocessing/notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974c403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Colab has a load of packages pre-loaded into the environment. Installing the additional ones we require here.\n",
    "!pip install seldon-deploy-sdk==1.4.1\n",
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f045f80",
   "metadata": {},
   "source": [
    "## Deploying the Model\n",
    "As we have seen in the previous sections the tweets are pre-processed using a variety of techniques. In order to account for this we have 2 options for how to account for the pre-processing logic in production:\n",
    "1. **Custom Model:** Incorporate the pre-processing directly in the `predict` method of a custom model. This provides simplicity when creating the deployment as there is only a single code base to worry about and a single component to be deployed.\n",
    "2. **Input Transformer:** Make use of a separate container to perform all of the input transformation and then pass the vectors to the model for prediction. The schematic below outlines how this would work. \n",
    "```\n",
    "            ________________________________________\n",
    "            |            SeldonDeployment          |\n",
    "            |                                      |\n",
    "Request -->  Input transformer   -->     Model --> Response\n",
    "            |  (Pre-processing)          (SKLearn) |\n",
    "            |______________________________________|\n",
    "```\n",
    "The use of an input transformer allows us to separate the pre-processing logic from the prediction logic. This means we can leverage the pre-packaged SKLearn server provided by Seldon to serve our model, and each of the components can be upgraded independently of one another. However, it does introduce additional complexity in the deployment which is generated, and how that then interacts with advanced monitoring components such as outlier and drift detectors. \n",
    "\n",
    "This workshop will focus on the generation of a **custom model for this case**, therefore we need to define an `__init__` and `predict` method which shall load and perform inference respectively in our new deployment. \n",
    "\n",
    "--------- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa02e77",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We then define our Seldon custom model. The component parts required to build the custom model are outlined below. Each of the files play a key part in building the eventual Seldon docker container.\n",
    "\n",
    "---\n",
    "### TweetSentiment.py\n",
    "This is the critical file as it contains the logic associated with the deployment wrapped as part of a class by the same name as the Python file. \n",
    "\n",
    "A key thing to note about the way this has been structured is that we have focused on making this deployment reusable. The `__init__` method accepts two custom predictor parameters; one for the saved model (`model_path`), and the other for the TF-IDF vectorizer (`tfidf_path`). \n",
    "\n",
    "The advantage of this is that it allows us to upgrade the model or vectorizer without having to re-build the container image. Additionally, if the logic was more general it could be used to accept a wider variety of objects for greater reusability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe4755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seldon_deploy_sdk import EnvironmentApi, Configuration, ApiClient, SeldonDeploymentsApi, OutlierDetectorApi, DriftDetectorApi, ModelMetadataServiceApi\n",
    "from seldon_deploy_sdk.auth import OIDCAuthenticator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile TweetSentiment.py\n",
    "\n",
    "from joblib import load\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# For downloading the model and OHE encoder from GCS\n",
    "from io import BytesIO\n",
    "from google.cloud import storage\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\", download_dir=\"./nltk\")\n",
    "nltk.data.path.append(\"./nltk\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TweetSentiment(object):\n",
    "\n",
    "    def __init__(self, model_path, tfidf_path):\n",
    "        logger.info(f\"Connecting to GCS\")\n",
    "        self.client = storage.Client.create_anonymous_client()\n",
    "        self.bucket = self.client.bucket('tom-seldon-examples')\n",
    "\n",
    "        logger.info(f\"Model name: {model_path}\")\n",
    "        self.model_path = model_path\n",
    "\n",
    "        logger.info(f\"TF-IDF Name: {tfidf_path}\")\n",
    "        self.tfidf_path = tfidf_path\n",
    "\n",
    "        logger.info(\"Loading model file and TF-IDF vectorizer.\")\n",
    "        self.load_deployment_artefacts()\n",
    "        self.ready = False\n",
    "\n",
    "    def load_deployment_artefacts(self):\n",
    "        logger.info(\"Loading model\")\n",
    "        model_file = BytesIO()\n",
    "        model_blob = self.bucket.get_blob(f'{self.model_path}')\n",
    "        model_blob.download_to_file(model_file)\n",
    "        self.model = load(model_file)\n",
    "\n",
    "        logger.info(\"Loading TF-IDF vectorizer\")\n",
    "        tfidf_file = BytesIO()\n",
    "        tfidf_blob = self.bucket.get_blob(f'{self.tfidf_path}')\n",
    "        tfidf_blob.download_to_file(tfidf_file)\n",
    "        self.tfidf = load(tfidf_file)\n",
    "        \n",
    "        self.ready = True\n",
    "\n",
    "    # Remove stop words\n",
    "    def remove_stopwords(self, text):\n",
    "        text = ' '.join([word for word in text.split() if word not in (stopwords.words('english'))])\n",
    "        return text\n",
    "\n",
    "    \n",
    "    def char(self, text):\n",
    "        substitute = re.sub(r'[^a-zA-Z]',' ',text)\n",
    "        return substitute\n",
    "\n",
    "    def predict(self, tweets, names=[], meta={}):\n",
    "        try:\n",
    "            if not self.ready:\n",
    "                self.load_deployment_artefacts()\n",
    "            else:\n",
    "                final_text = []\n",
    "\n",
    "                for text in tweets:\n",
    "                    # Apply functions to tweets\n",
    "                    text = self.remove_username(text)\n",
    "                    text = self.remove_url(text)\n",
    "                    text = self.remove_emoji(text)\n",
    "                    text = self.decontraction(text)\n",
    "                    text = self.seperate_alphanumeric(text)\n",
    "                    text = self.unique_char(self.cont_rep_char,text)\n",
    "                    text = self.char(text)\n",
    "                    text = text.lower()\n",
    "                    text = self.remove_stopwords(text)\n",
    "                    final_text.append(text)\n",
    "\n",
    "                logger.info(f\"Final text to be embedded: {final_text}\")\n",
    "                embeddings = self.tfidf.transform(final_text)\n",
    "                sentiment = self.model.predict(embeddings)\n",
    "                return sentiment\n",
    "\n",
    "        except Exception as ex:\n",
    "            logging.exception(f\"Failed during predict: {ex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f48e6",
   "metadata": {},
   "source": [
    "## Testing Locally\n",
    "In order to ensure that we have gotten the `TweetClassifier.py` working correctly we can use the `seldon_core` Python package to run our model locally and test the endpoint. \n",
    "```\n",
    "seldon-core-microservice TweetSentiment --service-type MODEL\n",
    "                                        --parameters='[{ \n",
    "                                                        \"name\": \"model_path\",\n",
    "                                                        \"value\": \"nlp-workshop/<YOUR NAME>/model.joblib\",\n",
    "                                                        \"type\": \"STRING\"\n",
    "                                                       }, {\n",
    "                                                        \"name\": \"tfidf_path\",\n",
    "                                                        \"value\": \"nlp-workshop/<YOUR NAME>/tfidf.joblib\",\n",
    "                                                        \"type\": \"STRING\"\n",
    "                                                       }]'\n",
    "```\n",
    "This endpoint can then be tested by posting cURL commands to the local endpoint: \n",
    "```\n",
    "curl -H 'Content-Type: application/json' -d '{\"data\": {\"ndarray\": [\"@united how can you not put my bag on plane to Seattle. Flight 1212. Waiting  in line to talk to someone about my bag. Status should matter.\"]}}' http://localhost:9000/api/v1.0/predictions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18dee70",
   "metadata": {},
   "source": [
    "### .s2i/environment\n",
    "In order for the Seldon base image to correctly convert your source code to an image it requires certain environment variables. In this case it is only 3 variables. \n",
    "* `MODEL_NAME`: The model name matches the name of the Python file and class which is created. \n",
    "* `SERVICE_TYPE`: Seldon allows you to create many different components each specialised for a different purpose e.g. `TRANSFORMER` for performing pre or post-processing steps. \n",
    "* `PERSISTENCE`: In some cases you would like to save the state of your deployments to Redis e.g. when scaling up multi-armed bandits\n",
    "\n",
    "This is our environment file:\n",
    "```\n",
    "MODEL_NAME=TweetSentiment\n",
    "SERVICE_TYPE=MODEL\n",
    "PERSISTENCE=0\n",
    "```\n",
    "---\n",
    "### requirements.txt\n",
    "List of Python packages which the deployment requires to run.\n",
    "```\n",
    "joblib\n",
    "pandas\n",
    "numpy\n",
    "seldon_core\n",
    "google-cloud-storage\n",
    "scikit-learn\n",
    "nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988862c0",
   "metadata": {},
   "source": [
    "## Building the Image\n",
    "\n",
    "We can then build the custom model using source 2 image technology. Firstly, installing it locally as per [the documentation](https://github.com/openshift/source-to-image), and then by running this command: \n",
    "```\n",
    "s2i build . seldonio/seldon-core-s2i-python3:1.12.0-dev tweet-sentiment:0.3\n",
    "```\n",
    "\n",
    "The built image is then pushed to Dockerhub where it can be pulled ready for deployment. In an enterprise setting, the container registry would be customised to the client's needs. \n",
    "```\n",
    "docker tag tweet-sentiment:0.3 tomfarrand/tweet-sentiment:0.3\n",
    "docker push tomfarrand/tweet-sentiment:0.3\n",
    "```\n",
    "\n",
    "In this case we will use my pre-built container image for speed and simplicity, which we can now deploy using the SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!s2i build . seldonio/seldon-core-s2i-python3:1.12.0-dev tweet-sentiment:0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf376647",
   "metadata": {},
   "source": [
    "## Using the SDK\n",
    "Now that we have our trained model artefact and preprocessor, alongside our custom built container we can now use the Seldon Deploy SDK to deploy our model! \n",
    "\n",
    "Initially we setup some authentication: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd51dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_IP = \"34.73.238.47\"\n",
    "\n",
    "config = Configuration()\n",
    "config.host = f\"http://{SD_IP}/seldon-deploy/api/v1alpha1\"\n",
    "config.oidc_client_id = \"sd-api\"\n",
    "config.oidc_server = f\"http://{SD_IP}/auth/realms/deploy-realm\"\n",
    "config.oidc_client_secret = \"sd-api-secret\"\n",
    "config.auth_method = 'client_credentials'\n",
    "\n",
    "def auth():\n",
    "    auth = OIDCAuthenticator(config)\n",
    "    config.id_token = auth.authenticate()\n",
    "    api_client = ApiClient(configuration=config, authenticator=auth)\n",
    "    return api_client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc14b53",
   "metadata": {},
   "source": [
    "Next, we define the parameters which we shall feed to the SDK.\n",
    "\n",
    "!!! Again, remember to fill in the `YOUR_NAME` parameter !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc7d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_NAME = \"jman\"\n",
    "MODEL_NAME = \"tweet-sentiment\"\n",
    "\n",
    "DEPLOYMENT_NAME = f\"airline-sentiment\"\n",
    "CONTAINER_NAME = f\"tomfarrand/tweet-sentiment:0.3\"\n",
    "\n",
    "NAMESPACE = \"seldon-demos\"\n",
    "\n",
    "CPU_REQUESTS = \"0.1\"\n",
    "MEMORY_REQUESTS = \"1Gi\"\n",
    "\n",
    "CPU_LIMITS = \"0.1\"\n",
    "MEMORY_LIMITS = \"1Gi\"\n",
    "\n",
    "MODEL_PATH = f\"nlp-workshop/tom-farrand/model.joblib\"\n",
    "TFIDF_PATH = f\"nlp-workshop/tom-farrand/tfidf.joblib\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1194566",
   "metadata": {},
   "source": [
    "The deployment specification is then defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67912bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mldeployment = {\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"labels\": {\n",
    "            \"fluentd\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"spec\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"annotations\": {\n",
    "            \"seldon.io/engine-seldon-log-messages-externally\": \"true\"\n",
    "        },\n",
    "        \"protocol\": \"seldon\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [\n",
    "                    {\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                                    \"image\": CONTAINER_NAME,\n",
    "                                    \"resources\": {\n",
    "                                        \"requests\": {\n",
    "                                            \"cpu\": CPU_REQUESTS,\n",
    "                                            \"memory\": MEMORY_REQUESTS\n",
    "                                        },\n",
    "                                        \"limits\": {\n",
    "                                            \"cpu\": CPU_LIMITS,\n",
    "                                            \"memory\": MEMORY_LIMITS\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"name\": \"default\",\n",
    "                \"replicas\": 1,\n",
    "                \"traffic\": 100,\n",
    "                \"graph\": {\n",
    "                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                    \"parameters\": [\n",
    "                        {\n",
    "                            \"name\":\"model_path\",\n",
    "                            \"value\":MODEL_PATH,\n",
    "                            \"type\":\"STRING\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\":\"tfidf_path\",\n",
    "                            \"value\":TFIDF_PATH,\n",
    "                            \"type\":\"STRING\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"children\": [],\n",
    "                    \"logger\": {\n",
    "                        \"mode\": \"all\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"status\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9630a",
   "metadata": {},
   "source": [
    "Finally, we deploy the model using a few simple API calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c822fb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'api_version': 'machinelearning.seldon.io/v1alpha2',\n",
       " 'kind': 'SeldonDeployment',\n",
       " 'metadata': {'annotations': None,\n",
       "              'cluster_name': None,\n",
       "              'creation_timestamp': None,\n",
       "              'deletion_grace_period_seconds': None,\n",
       "              'deletion_timestamp': None,\n",
       "              'finalizers': None,\n",
       "              'generate_name': None,\n",
       "              'generation': None,\n",
       "              'labels': {'fluentd': 'true'},\n",
       "              'managed_fields': None,\n",
       "              'name': 'airline-sentiment',\n",
       "              'namespace': 'seldon-demos',\n",
       "              'owner_references': None,\n",
       "              'resource_version': None,\n",
       "              'self_link': None,\n",
       "              'uid': None},\n",
       " 'spec': {'annotations': {'seldon.io/engine-seldon-log-messages-externally': 'true'},\n",
       "          'name': 'airline-sentiment',\n",
       "          'oauth_key': None,\n",
       "          'oauth_secret': None,\n",
       "          'predictors': [{'annotations': None,\n",
       "                          'component_specs': [{'hpa_spec': None,\n",
       "                                               'keda_spec': None,\n",
       "                                               'metadata': {'annotations': None,\n",
       "                                                            'cluster_name': None,\n",
       "                                                            'creation_timestamp': '2022-04-27T17:54:25Z',\n",
       "                                                            'deletion_grace_period_seconds': None,\n",
       "                                                            'deletion_timestamp': None,\n",
       "                                                            'finalizers': None,\n",
       "                                                            'generate_name': None,\n",
       "                                                            'generation': None,\n",
       "                                                            'labels': None,\n",
       "                                                            'managed_fields': None,\n",
       "                                                            'name': None,\n",
       "                                                            'namespace': None,\n",
       "                                                            'owner_references': None,\n",
       "                                                            'resource_version': None,\n",
       "                                                            'self_link': None,\n",
       "                                                            'uid': None},\n",
       "                                               'pdb_spec': None,\n",
       "                                               'replicas': None,\n",
       "                                               'spec': {'active_deadline_seconds': None,\n",
       "                                                        'affinity': None,\n",
       "                                                        'automount_service_account_token': None,\n",
       "                                                        'containers': [{'args': None,\n",
       "                                                                        'command': None,\n",
       "                                                                        'env': None,\n",
       "                                                                        'env_from': None,\n",
       "                                                                        'image': 'tomfarrand/tweet-sentiment:0.3',\n",
       "                                                                        'image_pull_policy': None,\n",
       "                                                                        'lifecycle': None,\n",
       "                                                                        'liveness_probe': None,\n",
       "                                                                        'name': 'airline-sentiment-container',\n",
       "                                                                        'ports': None,\n",
       "                                                                        'readiness_probe': None,\n",
       "                                                                        'resources': {'limits': {'cpu': '100m',\n",
       "                                                                                                 'memory': '1Gi'},\n",
       "                                                                                      'requests': {'cpu': '100m',\n",
       "                                                                                                   'memory': '1Gi'}},\n",
       "                                                                        'security_context': None,\n",
       "                                                                        'startup_probe': None,\n",
       "                                                                        'stdin': None,\n",
       "                                                                        'stdin_once': None,\n",
       "                                                                        'termination_message_path': None,\n",
       "                                                                        'termination_message_policy': None,\n",
       "                                                                        'tty': None,\n",
       "                                                                        'volume_devices': None,\n",
       "                                                                        'volume_mounts': None,\n",
       "                                                                        'working_dir': None}],\n",
       "                                                        'dns_config': None,\n",
       "                                                        'dns_policy': None,\n",
       "                                                        'enable_service_links': None,\n",
       "                                                        'ephemeral_containers': None,\n",
       "                                                        'host_aliases': None,\n",
       "                                                        'host_ipc': None,\n",
       "                                                        'host_network': None,\n",
       "                                                        'host_pid': None,\n",
       "                                                        'hostname': None,\n",
       "                                                        'image_pull_secrets': None,\n",
       "                                                        'init_containers': None,\n",
       "                                                        'node_name': None,\n",
       "                                                        'node_selector': None,\n",
       "                                                        'overhead': None,\n",
       "                                                        'preemption_policy': None,\n",
       "                                                        'priority': None,\n",
       "                                                        'priority_class_name': None,\n",
       "                                                        'readiness_gates': None,\n",
       "                                                        'restart_policy': None,\n",
       "                                                        'runtime_class_name': None,\n",
       "                                                        'scheduler_name': None,\n",
       "                                                        'security_context': None,\n",
       "                                                        'service_account': None,\n",
       "                                                        'service_account_name': None,\n",
       "                                                        'set_hostname_as_fqdn': None,\n",
       "                                                        'share_process_namespace': None,\n",
       "                                                        'subdomain': None,\n",
       "                                                        'termination_grace_period_seconds': None,\n",
       "                                                        'tolerations': None,\n",
       "                                                        'topology_spread_constraints': None,\n",
       "                                                        'volumes': None}}],\n",
       "                          'engine_resources': {'limits': None,\n",
       "                                               'requests': None},\n",
       "                          'explainer': None,\n",
       "                          'graph': {'children': None,\n",
       "                                    'endpoint': None,\n",
       "                                    'env_secret_ref_name': None,\n",
       "                                    'implementation': None,\n",
       "                                    'logger': {'mode': 'all', 'url': None},\n",
       "                                    'methods': None,\n",
       "                                    'model_uri': None,\n",
       "                                    'name': 'airline-sentiment-container',\n",
       "                                    'parameters': [{'name': 'model_path',\n",
       "                                                    'type': 'STRING',\n",
       "                                                    'value': 'nlp-workshop/tom-farrand/model.joblib'},\n",
       "                                                   {'name': 'tfidf_path',\n",
       "                                                    'type': 'STRING',\n",
       "                                                    'value': 'nlp-workshop/tom-farrand/tfidf.joblib'}],\n",
       "                                    'service_account_name': None,\n",
       "                                    'storage_initializer_image': None,\n",
       "                                    'type': None},\n",
       "                          'labels': None,\n",
       "                          'name': 'default',\n",
       "                          'replicas': 1,\n",
       "                          'shadow': None,\n",
       "                          'ssl': None,\n",
       "                          'svc_orch_spec': {'env': None,\n",
       "                                            'replicas': None,\n",
       "                                            'resources': None},\n",
       "                          'traffic': 100}],\n",
       "          'protocol': 'seldon',\n",
       "          'replicas': None,\n",
       "          'server_type': None,\n",
       "          'transport': None},\n",
       " 'status': {'address': None,\n",
       "            'annotations': None,\n",
       "            'conditions': None,\n",
       "            'deployment_status': None,\n",
       "            'description': None,\n",
       "            'observed_generation': None,\n",
       "            'replicas': None,\n",
       "            'service_status': None,\n",
       "            'state': None}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61951499",
   "metadata": {},
   "source": [
    "Once our endpoint becomes available we can then test the deployment using the following request: \n",
    "\n",
    "```\n",
    "{\n",
    "   \"data\":{\n",
    "      \"ndarray\":[\n",
    "         \"@united how can you not put my bag on plane to Seattle. Flight 1212. Waiting  in line to talk to someone about my bag. Status should matter.\"\n",
    "      ]\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f22c7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 279.948311,
   "end_time": "2021-11-15T08:58:48.814352",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-15T08:54:08.866041",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
