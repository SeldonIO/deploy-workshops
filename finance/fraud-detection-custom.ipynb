{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59cd5a7",
   "metadata": {},
   "source": [
    "# Hands-On Tabular Workshop: *Detecting Fraud in Transaction Data*\n",
    "\n",
    "This workshop is focused on the creation, deployment and monitoring of machine learning models for performing fraud detection. \n",
    "\n",
    "In this notebook you will be exploring the data, and training the machine learning models themself; in the form of an XGBoost classifier and a Scikit-learn Random Forest classifier. You will then begin to add the advanced monitoring and explainability which Seldon Alibi is famed for. \n",
    "\n",
    "The EDA and training of models within this notebook is heavily inspired by the fantastic work of Arjun Joshua, you can find the original [here](https://www.kaggle.com/arjunjoshua/predicting-fraud-in-financial-payment-services/notebook). \n",
    "\n",
    "-----------------------------------\n",
    "Firstly, you install and import the relevant packages which we will use throughout the exploration and training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15b8f6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install alibi==0.7.0\n",
    "!pip install alibi_detect==0.8.1\n",
    "!pip install dill\n",
    "!pip install seaborn\n",
    "!pip install seldon_deploy_sdk\n",
    "!pip install xgboost==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a540d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance, to_graphviz\n",
    "\n",
    "from seldon_deploy_sdk import Configuration, ApiClient, SeldonDeploymentsApi, ModelMetadataServiceApi, DriftDetectorApi, BatchJobsApi, BatchJobDefinition\n",
    "from seldon_deploy_sdk.auth import OIDCAuthenticator\n",
    "\n",
    "from alibi.explainers import AnchorTabular\n",
    "from alibi_detect.cd import MMDDrift\n",
    "from alibi_detect.utils.saving import save_detector, load_detector\n",
    "\n",
    "import dill\n",
    "\n",
    "# For repeatability\n",
    "randomState = 5\n",
    "np.random.seed(randomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd93193",
   "metadata": {},
   "source": [
    "You then download the dataset which you will be using for the workshop, and load it into a Pandas DataFrame. The dataset is stored in the public Google Cloud Storage bucket `kelly-seldon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83369e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://kelly-seldon/fraud-detection/transaction-data.csv data/transaction-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e182cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/transaction-data.csv')\n",
    "df = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n",
    "                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d69f0",
   "metadata": {},
   "source": [
    "It is worth taking a second to understand the features (columns of the table) within the dataset:\n",
    "* `step`: This is a time series data set i.e. money transfers occur over time. 1 step represents 1 hour, with a total of 744 steps equivalent to 30 days. \n",
    "* `type`: The type of transaction: CASH-IN, CASH-OUT, DEBIT, PAYMENT, TRANSFER.\n",
    "* `amount`: Amount of the transaction in local currency.\n",
    "* `nameOrig`: Customer name who started the transaction.\n",
    "* `oldBalanceOrig`: Initial balance before the transaction.\n",
    "* `newBalanceOrig`: New balance after the transaction.\n",
    "* `nameDest`: Customer name who is the recipient of the transaction.\n",
    "* `oldBalanceDest`: Initial balance of the recipient before the transaction.\n",
    "* `newBalanceDest`: New balance of the recipient after the transaction.\n",
    "* `isFraud`: This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control of customers accounts and trying to empty the funds by transferring to another account and then cashing out of the system.\n",
    "* `isFlaggedFraud`: The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.\n",
    "\n",
    "It is worth noting that this is a synthetically generated dataset and so does not represent real world transactions, but is based upon the behaviour of a supplied real world dataset. You can read more about the data used [here](https://www.kaggle.com/ntnu-testimon/paysim1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff22adaa",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "There are a number of data preparation steps which need to be performed prior to visualisation and model training. The first of which is to remove all transaction types apart from TRANSFER and CASH_OUT. These are the only transaction types where fraud occurs, and therefore the other types of transaction can be neglected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c810e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[(df.type == 'TRANSFER') | (df.type == 'CASH_OUT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f001b4",
   "metadata": {},
   "source": [
    "Next, you can remove a number of the feature columns which have no predictive power. These are the account name fields, as well as the `isFlaggedFraud` which has no clear relation to the other features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd320c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342194f",
   "metadata": {},
   "source": [
    "You can then encode the transaction type categorical feature as a binary. Transactions types of TRANSFER will be 0, meanwhile CASH_OUT transactions will be 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05709cfe",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.loc[X.type == 'TRANSFER', 'type'] = 0\n",
    "X.loc[X.type == 'CASH_OUT', 'type'] = 1\n",
    "X.type = X.type.astype(int) # convert dtype('O') to dtype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b4884",
   "metadata": {},
   "source": [
    "You now create the labels. This will simply be the `isFraud` field, and will be what your machine learning model attempts to predict based on the remaining transaction features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea02245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = X['isFraud']\n",
    "del X['isFraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7c12e",
   "metadata": {},
   "source": [
    "#### Working with Zero Balances\n",
    "\n",
    "The data has several transactions with zero balances in the destination account both before and after a non-zero amount is transacted. The fraction of such transactions, where zero likely denotes a missing value, is much larger in fraudulent (50%) compared to genuine transactions (0.06%).\n",
    "\n",
    "\n",
    "Since the destination account balances being zero is a strong indicator of fraud we replace the values of oldBalanceDest and newBalanceDest with -1 where they are 0 originally, but have a non-zero transfer between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d17fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[(X.oldBalanceDest == 0) & (X.newBalanceDest == 0) & (X.amount != 0), \\\n",
    "      ['oldBalanceDest', 'newBalanceDest']] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c41f81",
   "metadata": {},
   "source": [
    "The data also has several transactions with zero balances in the originating account both before and after a non-zero amount is transacted. Once again, the fraction of such transactions is much smaller in fraudulent (47%) compared to genuine transactions (0.3%). Once again, from similar reasoning as above, instead of imputing a numerical value we replace the value of 0 with -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[(X.oldBalanceOrig == 0) & (X.newBalanceOrig == 0) & (X.amount != 0), \\\n",
    "      ['oldBalanceOrig', 'newBalanceOrig']] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d0e90",
   "metadata": {},
   "source": [
    "Motivated by the possibility of zero-balances serving to differentiate between fraudulent and genuine transactions, create 2 new features (columns) recording errors in the originating and destination accounts for each transaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['errorBalanceOrig'] = X.newBalanceOrig + X.amount - X.oldBalanceOrig\n",
    "X['errorBalanceDest'] = X.oldBalanceDest + X.amount - X.newBalanceDest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc96b8a",
   "metadata": {},
   "source": [
    "## Data Visualisation\n",
    "\n",
    "Let's explore the data by generating a series of plots. \n",
    "\n",
    "First create a function which allows you to generate strip plots readily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59995950",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(X)\n",
    "\n",
    "def plotStrip(x, y, hue, figsize = (14, 9)):\n",
    "    \n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    colours = plt.cm.tab10(np.linspace(0, 1, 9))\n",
    "    with sns.axes_style('ticks'):\n",
    "        ax = sns.stripplot(x = x, y = y, \\\n",
    "             hue = hue, jitter = 0.4, marker = '.', \\\n",
    "             size = 4, palette = colours)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_xticklabels(['genuine', 'fraudulent'], size = 14)\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(2)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.legend(handles, ['Transfer', 'Cash out'], bbox_to_anchor=(1, 1), \\\n",
    "               loc=2, borderaxespad=0, fontsize = 14);\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b63ef",
   "metadata": {},
   "source": [
    "Let's compare how genuine and fraudulent transacations are distributed over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09178c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plotStrip(Y[:limit], X.step[:limit], X.type[:limit])\n",
    "ax.set_ylabel('time [hour]', size = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881a383",
   "metadata": {},
   "source": [
    "You can see that genuine transactions have a more regular pattern, occuring at intervals with periods in between which do not see any genuine transactions occuring. These periods could represent weekends or holidays resulting in businesses being closed. Meanwhile, the fraudulent transactions are far more evenly distributed, with no discernible pattern. \n",
    "\n",
    "Furthermore, it's clear that the majority of genuine transcations are of type CASH OUT, whereas fraudulent transactions feature TRANSFER types far more prominently. \n",
    "\n",
    "-----\n",
    "\n",
    "Next, compare the transfer amount distributions for genuine and fraudulent transctions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(X)\n",
    "ax = plotStrip(Y[:limit], X.amount[:limit], X.type[:limit], figsize = (14, 9))\n",
    "ax.set_ylabel('amount', size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4eb4c",
   "metadata": {},
   "source": [
    "There is no clear pattern between genuine and fraudulent transactions by simply considering the amount. However, it appears there is a ceiling on the limit of a fraudulent transaction (10,000,000).\n",
    "\n",
    "-----\n",
    "\n",
    "Finally, you visualise the feature you created earlier `errorBalanceDest`, which is simply calculated by taking the previous balance of the destination account, plus the amount which was transferred minus new balance in the account. \n",
    "\n",
    "Remember, that many of the fraudulent transactions we observed had 0 account balance both before and after a non-zero sum of money was transferred. Therefore, the `errorBalanceDest` of these transactions will be a positive number equivalent to the value of the transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(X)\n",
    "ax = plotStrip(Y[:limit], X.errorBalanceDest[:limit], X.type[:limit], \\\n",
    "              figsize = (14, 9))\n",
    "ax.set_ylabel('errorBalanceDest', size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf15ec4",
   "metadata": {},
   "source": [
    "From this figure we can see a clear distinction between genuine and fraudulent transactions with positive errorBalanceDest being recorded overwhelmingly more so for fraudulent transactions than genuine ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace675b",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Next you will train your predictor, to determine in an automated fashion whether a new transaction is fraudulent or not. \n",
    "\n",
    "You will be using an XGBoost classifier as it is naturally suited to handling such an imbalanced dataset, whereby only 0.3% of the transactions are fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f75081",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfraud = X.loc[Y == 1]\n",
    "XnonFraud = X.loc[Y == 0]\n",
    "\n",
    "print('skew = {}'.format( len(Xfraud) / float(len(X)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9fec1",
   "metadata": {},
   "source": [
    "You split your data into training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d435d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.2, random_state = randomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1c67c",
   "metadata": {},
   "source": [
    "You also weight the positive class (fraudulent) more than the negative class (genuine) to help account for the overrepresentation of genuine transactions in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd513a0",
   "metadata": {},
   "source": [
    "You then train and score an XGBoost classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long computation in this cell (~3 minutes)\n",
    "\n",
    "clf = XGBClassifier(max_depth = 3, scale_pos_weight = weights, n_jobs = 4, use_label_encoder=False)\n",
    "probabilities = clf.fit(trainX, trainY).predict_proba(testX)\n",
    "print('AUPRC = {}'.format(average_precision_score(testY, probabilities[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b06515d",
   "metadata": {},
   "source": [
    "A very impressive 0.99 AUPRC! Which means your classifier is accurately distinguishing between transactions. \n",
    "\n",
    "You can visualise the features which are most important to your new XGBoost classifier as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (14, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colours = plt.cm.Set1(np.linspace(0, 1, 9))\n",
    "\n",
    "ax = plot_importance(clf, height = 1, color = colours, grid = False, \\\n",
    "                     show_values = False, importance_type = 'cover', ax = ax);\n",
    "for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(2)\n",
    "        \n",
    "ax.set_xlabel('importance score', size = 16);\n",
    "ax.set_ylabel('features', size = 16);\n",
    "ax.set_yticklabels(ax.get_yticklabels(), size = 12);\n",
    "ax.set_title('Plotting the models most important features', size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a94f89",
   "metadata": {},
   "source": [
    "You can now save your model, and upload it to an artefact store (in this case a Google storage bucket) ready for deployment.\n",
    "\n",
    "You will be making use of the pre-packaged XGBoost model server, and therefore Seldon expects your classifier to be saved as `model.bst`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275beb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('model.bst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36093c30",
   "metadata": {},
   "source": [
    "You will now upload our saved model file to a Google storage bucket. \n",
    "\n",
    "### ⚠️ IMPORTANT ⚠️\n",
    "Make sure you fill in the YOUR_NAME variable to ensure you're not overwriting existing artefacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb251d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_NAME = \"\"\n",
    "\n",
    "!gsutil cp model.bst gs://kelly-seldon/fraud-detection/models/{YOUR_NAME}/model.bst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50aae61",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "We can now deploy our models to the dedicated Seldon Deploy cluster that we have configured for this workshop. To do this, we will interact with the Seldon Deploy SDK.\n",
    "\n",
    "Firstly, we need to set up the configuration and authentication required to access the cluster.\n",
    "\n",
    "⚠️ Make sure to fill in the following in the below cell if not already filled in:\n",
    "\n",
    "- SD_DOM variable - Ensure to change this to the domain name of the cluster you are using.\n",
    "- CLIENT_SECRET variable - this will either be sd-api-secret or an alternative secret provided during the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_DOM = \"\"\n",
    "CLIENT_SECRET = \"\"\n",
    "\n",
    "config = Configuration()\n",
    "config.host = f\"https://{SD_DOM}/seldon-deploy/api/v1alpha1\"\n",
    "config.oidc_client_id = \"sd-api\"\n",
    "config.oidc_server = f\"https://{SD_DOM}/auth/realms/deploy-realm\"\n",
    "config.oidc_client_secret = f\"{CLIENT_SECRET}\"\n",
    "config.auth_method = \"auth_code\"\n",
    "\n",
    "def auth():\n",
    "    auth = OIDCAuthenticator(config)\n",
    "    config.id_token = auth.authenticate()\n",
    "    api_client = ApiClient(configuration=config, authenticator=auth)\n",
    "    return api_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8915408",
   "metadata": {},
   "source": [
    "Now you have configured the IP correctly as well as setup your authentication function you can describe the deployment you would like to create. \n",
    "\n",
    "For the `MODEL_LOCATION` you do not need to specify the path all the way up to `model.bst` e.g. if you saved your classifier under `gs://kelly-seldon/fraud-detection/models/kelly-spry/model.bst` your `MODEL_LOCATION` should be `gs://kelly-seldon/fraud-detection/models/kelly-spry` and Seldon will automatically pick up the classifier artifact stored there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc49323",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_NAME = f\"{YOUR_NAME}-fraud\"\n",
    "NAMESPACE = \"seldon-gitops\"\n",
    "MODEL_LOCATION = f\"gs://kelly-seldon/fraud-detection/models/{YOUR_NAME}\"\n",
    "\n",
    "PREPACKAGED_SERVER = \"XGBOOST_SERVER\"\n",
    "\n",
    "CPU_REQUESTS = \"1\"\n",
    "MEMORY_REQUESTS = \"1Gi\"\n",
    "\n",
    "CPU_LIMITS = \"1\"\n",
    "MEMORY_LIMITS = \"1Gi\"\n",
    "\n",
    "mldeployment = {\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"labels\": {\n",
    "            \"fluentd\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"spec\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"annotations\": {\n",
    "            \"seldon.io/engine-seldon-log-messages-externally\": \"true\"\n",
    "        },\n",
    "        \"protocol\": \"seldon\",\n",
    "        \"transport\": \"rest\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [\n",
    "                    {\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                                    \"resources\": {\n",
    "                                        \"requests\": {\n",
    "                                            \"cpu\": CPU_REQUESTS,\n",
    "                                            \"memory\": MEMORY_REQUESTS\n",
    "                                        },\n",
    "                                        \"limits\": {\n",
    "                                            \"cpu\": CPU_LIMITS,\n",
    "                                            \"memory\": MEMORY_LIMITS\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"name\": \"default\",\n",
    "                \"replicas\": 1,\n",
    "                \"traffic\": 100,\n",
    "                \"graph\": {\n",
    "                    \"implementation\": PREPACKAGED_SERVER,\n",
    "                    \"modelUri\": MODEL_LOCATION,\n",
    "                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                    \"endpoint\": {\n",
    "                        \"type\": \"REST\"\n",
    "                    },\n",
    "                    \"parameters\": [],\n",
    "                    \"children\": [],\n",
    "                    \"logger\": {\n",
    "                        \"mode\": \"all\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"status\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263e40c",
   "metadata": {},
   "source": [
    "You can now invoke the `SeldonDeploymentsApi` and create a new Seldon Deployment. \n",
    "\n",
    "Time for you to get your hands dirty. You will use the Seldon Deploy SDK to create a new Seldon deployment. You can find the reference documentation [here](https://github.com/SeldonIO/seldon-deploy-sdk/blob/master/python/README.md). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e347ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b2e79",
   "metadata": {},
   "source": [
    "You can access the Seldon Deploy cluster and view your freshly created deployment here. Ensure you replace the `XXXXX` with the IP for the cluster you're using:\n",
    "\n",
    "* URL: http://XXXXX/seldon-deploy/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94449993",
   "metadata": {},
   "source": [
    "## Adding a Prediction Schema & Metadata\n",
    "Seldon Deploy has a model catalog where all deployed models are automatically registered. The model catalog can store custom metadata as well as prediction schemas for your models. \n",
    "\n",
    "Metadata promotes lineage from across different machine learning systems, aids knowledge transfer between teams, and allows for faster deployment. Meanwhile, prediction schemas allow Seldon Deploy to automatically profile tabular data into histograms, allowing for filtering on features to explore trends. \n",
    "\n",
    "In order to effectively construct a prediction schema Seldon has the [ML Prediction Schema](https://github.com/SeldonIO/ml-prediction-schema) project. The first step is to determine your datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde541bb",
   "metadata": {},
   "source": [
    "From this you can construct the prediction schema object below, which maps the data types to the requests and responses which the model returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_schema = {\n",
    "    \"requests\": [\n",
    "        {\n",
    "            \"name\": \"step\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"INT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"type\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"INT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"amount\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"FLOAT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"oldBalanceOrig\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"FLOAT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"newBalanceOrig\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"FLOAT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"oldBalanceDest\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"FLOAT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"newBalanceDest\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"FLOAT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"errorBalanceOrig\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"FLOAT\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"errorBalanceDest\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"FLOAT\"\n",
    "        }\n",
    "    ],\n",
    "    \"responses\": [\n",
    "        {\n",
    "            \"name\": \"Likelihood of Fraud\",\n",
    "            \"type\": \"REAL\",\n",
    "            \"data_type\": \"FLOAT\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf9d55",
   "metadata": {},
   "source": [
    "You then add the prediction schema to the wider model catalog metadata. This includes information such as the model storage location, the name, who authored the model etc. The metadata tags and metrics which can be associated with a model are freeform and can therefore be determined based upon the use case which is being developed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catalog_metadata = {\n",
    "      \"URI\": MODEL_LOCATION,\n",
    "      \"name\": f\"{DEPLOYMENT_NAME}-model\",\n",
    "      \"version\": \"v1.0\",\n",
    "      \"artifactType\": \"XGBOOST\",\n",
    "      \"taskType\": \"fraud classification\",\n",
    "      \"tags\": {\n",
    "        \"auto_created\": \"true\",\n",
    "        \"author\": f\"{YOUR_NAME}\"\n",
    "      },\n",
    "      \"metrics\": {},\n",
    "      \"project\": \"default\",\n",
    "      \"prediction_schema\": prediction_schema\n",
    "    }\n",
    "\n",
    "model_catalog_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a25c1",
   "metadata": {},
   "source": [
    "Next, using the metadata API you can add this to the model which you have just created in Seldon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742bc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_api = ModelMetadataServiceApi(auth())\n",
    "metadata_api.model_metadata_service_update_model_metadata(model_catalog_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c4b87",
   "metadata": {},
   "source": [
    "You can then list the metadata via the API, or view it in the UI, to confirm that it has been successfully added to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60524f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_response = metadata_api.model_metadata_service_list_model_metadata(uri=MODEL_LOCATION)\n",
    "metadata_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d37f0",
   "metadata": {},
   "source": [
    "You can now send requests to your model. As an example of a normal request:\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"names\": [\"step\", \"type\", \"amount\", \"oldBalanceOrig\", \"newBalanceOrig\",\n",
    "                  \"oldBalanceDest\", \"newBalanceDest\", \"errorBalanceOrig\", \"errorBalanceDest\"],\n",
    "        \"ndarray\": [\n",
    "            [205, 1, 63243.44, -1.00, -1.00, 1853683.32, 1916926.76, 63243.44, 0]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "And a fraudulent transaction too:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"names\": [\"step\", \"type\", \"amount\", \"oldBalanceOrig\", \"newBalanceOrig\",\n",
    "                  \"oldBalanceDest\", \"newBalanceDest\", \"errorBalanceOrig\", \"errorBalanceDest\"],\n",
    "        \"ndarray\": [\n",
    "            [629, 1, 2433009.28, 2433009.28, 0.00, 0.00, 2433009.28, 0.00, 0.00]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159200d4",
   "metadata": {},
   "source": [
    "# Drift Detection\n",
    "\n",
    "In this example you will use Alibi Detect to train a custom drift detector which can flag when the underlying input data distribution has shifted. This can inform decisions about re-training or prompt deeper investigation into data/model behaviours.\n",
    "\n",
    "Seldon Deploy also allows you to setup alerts when drift is detected.\n",
    "\n",
    "In this example you will use the Maximum Mean Discrepancy method. Covariate or input drift detection relies on creating a distance measure between two distributions; a reference distribution and a new distribution. The MMD drift detector is no different; the mean embeddings of your features are used to generate the distributions and then the distance between them is measured. The training data is used to calculate the reference distribution, while the new distribution comes from your inference data.\n",
    "\n",
    "More technically, a reproducing kernel Hilbert space is used to generate the mean embeddings, by mapping the highly complex feature space within which most machine learning models operate to a linear Euclidean space. A radial basis function kernel is then used to measure the distance between the two embeddings, and the signifiance of the drift is calculated as a p-value using permutation/resampling tests. More details can be found here.\n",
    "\n",
    "In this case you will train your drift detector on a sample of 5000 instances from the training set. This has been picked for convenience and speed of training in the workshop, and if this was a production case you would likely want to use the entirety of the training set, or a statistically significant segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = MMDDrift(trainX.iloc[:5000].to_numpy(), backend='tensorflow', p_val=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdea657",
   "metadata": {},
   "source": [
    "Once you have successfully trained your drift detector you can send it batches of data from the test set and test whether or not drift has occurred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232dbc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cd.predict(testX.iloc[100:200].to_numpy(), return_p_val=True, return_distance=True)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b00d0",
   "metadata": {},
   "source": [
    "You can then save the drift detector, and upload it to the GS bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_detector(cd, \"fraud-drift-detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b310e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp -r fraud-drift-detector gs://kelly-seldon/fraud-detection/models/{YOUR_NAME}/fraud-drift-detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc7b73",
   "metadata": {},
   "source": [
    "Then, we can use the Seldon Deploy SDK to deploy our newly configured drift detector. We can define the config for the drift detector and then call the `DriftDetectorApi` to create the drift detector seldon deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DD_URI = f\"gs://kelly-seldon/fraud-detection/models/{YOUR_NAME}/fraud-drift-detector\"\n",
    "DD_NAME = \"ee-dd\"\n",
    "\n",
    "dd_config = {'config': {'basic': \n",
    "                        {'drift_batch_size': '5',\n",
    "                         'storage_uri': DD_URI},\n",
    "                        'deployment': {'protocol': 'seldon.http'}\n",
    "                        },\n",
    "             'deployment_name': DEPLOYMENT_NAME,\n",
    "             'detector_type': 'drift',\n",
    "             'name': DD_NAME,\n",
    "             'namespace': NAMESPACE\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c084199",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_api = DriftDetectorApi(auth())\n",
    "dd_api.create_drift_detector_seldon_deployment(name=DEPLOYMENT_NAME, namespace=NAMESPACE, detector_data=dd_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e2698",
   "metadata": {},
   "source": [
    "We could test our drift detector by running a batch job, but for ease here, we will just run the same request through our model around 20 times. We will then be able to view drift data on the Seldon Deploy UI.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"names\": [\"step\", \"type\", \"amount\", \"oldBalanceOrig\", \"newBalanceOrig\",\n",
    "                  \"oldBalanceDest\", \"newBalanceDest\", \"errorBalanceOrig\", \"errorBalanceDest\"],\n",
    "        \"ndarray\": [\n",
    "            [629, 1, 2433009.28, 2433009.28, 0.00, 0.00, 2433009.28, 0.00, 0.00]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88995b",
   "metadata": {},
   "source": [
    "# Explainer\n",
    "Next, you will train an explainer to glean deeper insights into the decisions being made by your model. \n",
    "\n",
    "You will make use of the Anchors algorithm, which has a [production grade implementation available](https://docs.seldon.io/projects/alibi/en/stable/methods/Anchors.html) using the Seldon Alibi Explain library. \n",
    "\n",
    "The first step will be to write a simple prediction function which the explainer can call in order to query your XGBoost model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(x):\n",
    "    return clf.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ef3c1",
   "metadata": {},
   "source": [
    "You then initialise your Anchor explainer, using the AnchorTabular flavour provided by Alibi due to your data modality. \n",
    "\n",
    "The AnchorTabular class expects the prediction function which you defined above, as well as a list of the feature names. You can find a sample notebook in the Alibi docs [here](https://docs.seldon.io/projects/alibi/en/stable/examples/anchor_tabular_adult.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb19ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(trainX.columns)\n",
    "explainer = AnchorTabular(predict_fn, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa4361",
   "metadata": {},
   "source": [
    "You now need to fit your explainer object around some data so that it can learn to generate explanations based upon said data. \n",
    "\n",
    "As the training set is highly imbalanced (only a tiny fraction of the datapoints are fraudulent transactions) you create a new balanced set which is 50/50 normal/fraud transactions. This helps you to generate descriptive and useful explanations for both fraudulent and normal transactions.*\n",
    "\n",
    "In the code block below you generate the new balanced set, and convert it to a numpy array as this is the type which Alibi expects. \n",
    "\n",
    "\\*It is possible to generate a working explainer based upon the original dataset, but the anchors it identifies are not specific when considering normal transactions. The empty anchor is only ever returned due to the skew in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e70f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_set = pd.concat([Xfraud, XnonFraud.iloc[:len(Xfraud)]]).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d325d3",
   "metadata": {},
   "source": [
    "You then fit our explainer to your newly balanced data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.fit(balanced_set, disc_perc=(25, 50, 75)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8516dbb",
   "metadata": {},
   "source": [
    "You can now test your explainer on the test set, and view the explanations it begins to generate. Feel free to change the value of `idx` to see how it impacts the explanation generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef5fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 10\n",
    "\n",
    "testX_array = testX.to_numpy()\n",
    "\n",
    "class_names = [\"Normal\", \"Fraudulent\"]\n",
    "print('Prediction: ', class_names[explainer.predictor(testX_array[idx].reshape(1, -1))[0]])\n",
    "\n",
    "explanation = explainer.explain(testX_array[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1eb89",
   "metadata": {},
   "source": [
    "Explicitly testing a fraudulent transaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction: ', class_names[explainer.predictor(testX.loc[6272989].to_numpy().reshape(1, -1))[0]])\n",
    "\n",
    "explanation = explainer.explain(testX.loc[6272989].to_numpy(), threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048d98d",
   "metadata": {},
   "source": [
    "You now save your explainer, and upload it to the GS bucket. You can use the explainer's built-in save method to do this easily and reproducibly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.save(\"fraud-explainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3a7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp -r fraud-explainer gs://kelly-seldon/fraud-detection/models/{YOUR_NAME}/fraud-explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4dfc54",
   "metadata": {},
   "source": [
    "## Deploying the Explainer\n",
    "\n",
    "You can now deploy our explainer alongside our model. First you define the explainer configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bcdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLAINER_TYPE = \"AnchorTabular\"\n",
    "EXPLAINER_URI = f\"gs://kelly-seldon/fraud-detection/models/{YOUR_NAME}/fraud-explainer\"\n",
    "\n",
    "explainer_spec = {\n",
    "                    \"type\": EXPLAINER_TYPE,\n",
    "                    \"modelUri\": EXPLAINER_URI,\n",
    "                    \"containerSpec\": {\n",
    "                        \"name\": \"\",\n",
    "                        \"resources\": {}\n",
    "                    }\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17064a7",
   "metadata": {},
   "source": [
    "You can then insert this additional configuration into your original `mldeployment` specification which you defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mldeployment['spec']['predictors'][0]['explainer'] = explainer_spec\n",
    "mldeployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c953922",
   "metadata": {},
   "source": [
    "You then deploy the explainer to the Seldon Deploy cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48439dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c988a0f",
   "metadata": {},
   "source": [
    "You can now use an example request to generate both a prediction and then a subsequent explanation. \n",
    "\n",
    "\n",
    "A fraudulent transaction:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"names\": [\"step\", \"type\", \"amount\", \"oldBalanceOrig\", \"newBalanceOrig\",\n",
    "                  \"oldBalanceDest\", \"newBalanceDest\", \"errorBalanceOrig\", \"errorBalanceDest\"],\n",
    "        \"ndarray\": [\n",
    "            [629.0, 1.0, 2433009.28, 2433009.28, 0.0, 0.0, 2433009.28, 0.0, 0.0]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd763f7-e944-4fa0-b761-96a0fb013215",
   "metadata": {},
   "source": [
    "# A/B Testing\n",
    "## Train a second model\n",
    "\n",
    "We will train a second fraud detection mode using Sklearn, the Sklearn server is another of Seldon's prepackaged servers, therefore again we only need to save our model in object storage to be able to deploy it with Seldon. \n",
    "\n",
    "Firstly, we can compute weights using sklearns compute_class_weight `compute_class_weight` function and format them into the dictionary required as input to our Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefbd9e-e6e2-4881-b41b-13420d58d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_weights = class_weight.compute_class_weight(class_weight=\"balanced\", classes=Y.unique(), y=Y)\n",
    "sk_weights = {1: sk_weights[0], 0: sk_weights[1]}\n",
    "sk_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531c76c-6c17-4d40-8772-b45bc9360a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long computation in this cell (~ 5 mins)\n",
    "\n",
    "sk_clf = RandomForestClassifier(n_estimators=100, max_depth=3, class_weight=sk_weights)\n",
    "probs = sk_clf.fit(trainX, trainY).predict_proba(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39854f9-e1ca-468b-b8be-84c65df597e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUPRC = {}'.format(average_precision_score(testY, probs[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7906a9-7a3e-430b-9eee-cf80c7e72965",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(sk_clf, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecaf38-29a6-42d1-91e0-18c41e0b4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp model.joblib gs://kelly-seldon/fraud-detection/models/{YOUR_NAME}/model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1f01c-2002-4fbd-af02-d0afce738ef6",
   "metadata": {},
   "source": [
    "## Deploy second model as a Canary\n",
    "\n",
    "Seldon supports a number of advanced deployment patterns, including Multi-armed bandits, A/B testing, Canary deployments and Shadow deployments.\n",
    "\n",
    "Here, we will deploy our Sklearn Random Forest Classifier as a Canary Deployment and we will direct 30% of traffic to this model.\n",
    "\n",
    "We will deploy our Canary model using the Deployment Wizard on the UI.\n",
    "\n",
    "We need to set the following field values:\n",
    "\n",
    "**'Add a Canary'** tab:\n",
    "\n",
    "* Runtime - \"SciKit Learn\"\n",
    "* Model URI - gs://kelly-seldon/fraud-detection/models/{YOUR_NAME}/model.joblib\n",
    "* Canary Traffic Percentage - 30%\n",
    "\n",
    "Now you can click through the remaining optional tabs and launch the updated Seldon Deployment.\n",
    "\n",
    "Once our canary model is available, we can make predictions and then view live requests and resource monitoring on the \"Dashboard\" tab in the Deployment UI for both models running in production.\n",
    "\n",
    "We will assume that this model has been running in production for some time and it is performing better than our default model.\n",
    "\n",
    "We can then finally go ahead and promote the canary model to be the default model in the deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3076e1",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "Thank you for sticking it out to the end of the workshop! \n",
    "\n",
    "As a recap you have done the following: \n",
    "1. Cleaned and explored a set of transaction data.\n",
    "2. Trained an XGBoost model to distinguish between normal and fraudulent payments. \n",
    "3. Added metadata and a prediction schema. \n",
    "4. Trained and deployed a drift detector to understand when your data changes. \n",
    "5. Added an explainer to gain deeper insights into the model's behaviour.\n",
    "6. Trained an Sklearn model and deployed this as a canary.\n",
    "\n",
    "Not a bad list. Well done, you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af15aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
