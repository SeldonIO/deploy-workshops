{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59cd5a7",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "\n",
    "This series of notebooks is focused on the creation, deployment, monitoring and management of a machine learning model for performing fraud detection. \n",
    "\n",
    "In this notebook we will be exploring the data, and training the machine learning model itself; in the form of an XGBoost classifier. \n",
    "\n",
    "This notebook and code within it is heavily inspired by the fantastic work of Arjun Joshua, you can find the original here: https://www.kaggle.com/arjunjoshua/predicting-fraud-in-financial-payment-services/notebook\n",
    "\n",
    "-----------------------------------\n",
    "First, we install and import the relevant packages which we will use throughout the exploration and training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c702bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!conda create --name=seldon-workshop python=3.6.8 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704a540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance, to_graphviz\n",
    "\n",
    "from seldon_deploy_sdk import Configuration, ApiClient, SeldonDeploymentsApi, OutlierDetectorApi, DriftDetectorApi\n",
    "from seldon_deploy_sdk.auth import OIDCAuthenticator\n",
    "\n",
    "from alibi.explainers import AnchorTabular\n",
    "import dill\n",
    "\n",
    "# For repeatability\n",
    "randomState = 5\n",
    "np.random.seed(randomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd93193",
   "metadata": {},
   "source": [
    "We then download the dataset we will be using for the workshop, and load it into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83369e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://tom-seldon-examples/workshops/financial-services/data/PS_20174392719_1491204439457_log.csv...\n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "/ [1 files][470.7 MiB/470.7 MiB]    6.6 MiB/s                                   \n",
      "Operation completed over 1 objects/470.7 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://tom-seldon-examples/workshops/financial-services/data/PS_20174392719_1491204439457_log.csv data/PS_20174392719_1491204439457_log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e182cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/PS_20174392719_1491204439457_log.csv')\n",
    "df = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n",
    "                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d69f0",
   "metadata": {},
   "source": [
    "It is worth taking a second to understand the features (columns of the table) within the dataset:\n",
    "* `step`: This is a time series data set i.e. money transfers occur over time. 1 step represents 1 hour, with a total of 744 steps equivalent to 30 days. \n",
    "* `type`: The type of transaction: CASH-IN, CASH-OUT, DEBIT, PAYMENT, TRANSFER.\n",
    "* `amount`: Amount of the transaction in local currency.\n",
    "* `nameOrig`: Customer name who started the transaction.\n",
    "* `oldBalanceOrig`: Initial balance before the transaction.\n",
    "* `newBalanceOrig`: New balance after the transaction.\n",
    "* `nameDest`: Customer name who is the recipient of the transaction.\n",
    "* `oldBalanceDest`: Initial balance of the recipient before the transaction.\n",
    "* `newBalanceDest`: New balance of the recipient after the transaction.\n",
    "* `isFraud`: This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.\n",
    "* `isFlaggedFraud`: The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.\n",
    "\n",
    "It is worth noting that this is a synthetically generated dataset and so does not represent real world transactions, but is based upon the behaviour of a supplied real world dataset. You can read more about the data used [here](https://www.kaggle.com/ntnu-testimon/paysim1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff22adaa",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "There are a number of data preparation steps which need to be performed prior to visualisation and model training. The first of which is to remove all transaction types apart from TRANSFER and CASH_OUT. These are the only transaction types where fraud occurs, and therefore the other types of transaction can be neglected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c810e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[(df.type == 'TRANSFER') | (df.type == 'CASH_OUT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f001b4",
   "metadata": {},
   "source": [
    "Next, we can remove a number of the feature columns which have no predictive power. These are the account name fields, as well as the `isFlaggedFraud` which has no clear relation to the other features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd320c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342194f",
   "metadata": {},
   "source": [
    "We then encode the transaction type categorical feature as a binary. Transactions types of TRANSFER will be 0, meanwhile CASH_OUT transactions will be 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05709cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X.type == 'TRANSFER', 'type'] = 0\n",
    "X.loc[X.type == 'CASH_OUT', 'type'] = 1\n",
    "X.type = X.type.astype(int) # convert dtype('O') to dtype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b4884",
   "metadata": {},
   "source": [
    "We now create our labels. This will simply be the `isFraud` field, and will be what our machine learning model attempts to predict based on the remaining transaction features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea02245",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X['isFraud']\n",
    "del X['isFraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7c12e",
   "metadata": {},
   "source": [
    "#### Working with Zero Balances\n",
    "\n",
    "The data has several transactions with zero balances in the destination account both before and after a non-zero amount is transacted. The fraction of such Thetransactions, where zero likely denotes a missing value, is much larger in fraudulent (50%) compared to genuine transactions (0.06%).\n",
    "\n",
    "\n",
    "Since the destination account balances being zero is a strong indicator of fraud we replace the values of oldBalanceDest and newBalanceDest with -1 where they are 0 originally, but have a non-zero transfer between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d17fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[(X.oldBalanceDest == 0) & (X.newBalanceDest == 0) & (X.amount != 0), \\\n",
    "      ['oldBalanceDest', 'newBalanceDest']] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c41f81",
   "metadata": {},
   "source": [
    "The data also has several transactions with zero balances in the originating account both before and after a non-zero amount is transacted. In this case, the fraction of such transactions is much smaller in fraudulent (0.3%) compared to genuine transactions (47%). Once again, from similar reasoning as above, instead of imputing a numerical value we replace the value of 0 with -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[(X.oldBalanceOrig == 0) & (X.newBalanceOrig == 0) & (X.amount != 0), \\\n",
    "      ['oldBalanceOrig', 'newBalanceOrig']] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d0e90",
   "metadata": {},
   "source": [
    "Motivated by the possibility of zero-balances serving to differentiate between fraudulent and genuine transactions, we create 2 new features (columns) recording errors in the originating and destination accounts for each transaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['errorBalanceOrig'] = X.newBalanceOrig + X.amount - X.oldBalanceOrig\n",
    "X['errorBalanceDest'] = X.oldBalanceDest + X.amount - X.newBalanceDest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc96b8a",
   "metadata": {},
   "source": [
    "## Data Visualisation\n",
    "\n",
    "Let's explore the data by generating a series of plots. \n",
    "\n",
    "First we create a function which allows us to generate strip plots readily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59995950",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(X)\n",
    "\n",
    "def plotStrip(x, y, hue, figsize = (14, 9)):\n",
    "    \n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    colours = plt.cm.tab10(np.linspace(0, 1, 9))\n",
    "    with sns.axes_style('ticks'):\n",
    "        ax = sns.stripplot(x = x, y = y, \\\n",
    "             hue = hue, jitter = 0.4, marker = '.', \\\n",
    "             size = 4, palette = colours)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_xticklabels(['genuine', 'fraudulent'], size = 14)\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(2)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        plt.legend(handles, ['Transfer', 'Cash out'], bbox_to_anchor=(1, 1), \\\n",
    "               loc=2, borderaxespad=0, fontsize = 14);\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b63ef",
   "metadata": {},
   "source": [
    "Let's compare how genuine and fraudlent transacations are distributed over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09178c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plotStrip(Y[:limit], X.step[:limit], X.type[:limit])\n",
    "ax.set_ylabel('time [hour]', size = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881a383",
   "metadata": {},
   "source": [
    "We can see that genuine transactions have a more regular pattern, occuring at intervals with periods in between which do not see any genuine transactions occuring. These periods could represent weekends or holidays resulting in businesses being closed. Meanwhile, the fraudulent transactions are far more evenly distributed, with no discernible pattern. \n",
    "\n",
    "Furthermore, it's clear that the majority of genuine transcations are of type CASH OUT, whereas fraudulent transactions feature TRANSFER types far more prominently. \n",
    "\n",
    "-----\n",
    "\n",
    "Next, we compare the transfer amount distributions for genuine and fraudulent transctions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd70a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "limit = len(X)\n",
    "ax = plotStrip(Y[:limit], X.amount[:limit], X.type[:limit], figsize = (14, 9))\n",
    "ax.set_ylabel('amount', size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4eb4c",
   "metadata": {},
   "source": [
    "There is no clear pattern between genuine and fraudulent transactions by simply considering the amount. However, it appears there is a ceiling on the limit of a fraudulent transaction (10,000,000).\n",
    "\n",
    "-----\n",
    "\n",
    "Finally, we visualise the feature we created earlier `errorBalanceDest`, which is simply calculated by taking the previous balance of the destination account, plus the amount which was transferred minus new balance in the account. \n",
    "\n",
    "Remember, that many of the fraudulent transactions we observed had 0 account balance both before and after a non-zero sum of money was transferred. Therefore, the `errorBalanceDest` of these transactions will be a positive number equivalent to the value of the transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(X)\n",
    "ax = plotStrip(Y[:limit], X.errorBalanceDest[:limit], X.type[:limit], \\\n",
    "              figsize = (14, 9))\n",
    "ax.set_ylabel('errorBalanceDest', size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf15ec4",
   "metadata": {},
   "source": [
    "From this figure we can see a clear distinction between genuine and fraudulent transactions with positive errorBalanceDest being recorded overwhelmingly more so for fraudulent transactions than genuine ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cace675b",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Next we will train our predictor, to determine in an automated fashion whether a new transaction is fraudulent or not. \n",
    "\n",
    "We will be using an XGBoost classifier as it is naturally suited to handling such an imbalanced dataset, whereby only 0.3% of the transactions are fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f75081",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfraud = X.loc[Y == 1]\n",
    "XnonFraud = X.loc[Y == 0]\n",
    "\n",
    "print('skew = {}'.format( len(Xfraud) / float(len(X)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9fec1",
   "metadata": {},
   "source": [
    "We split our data into training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d435d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.2, random_state = randomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1c67c",
   "metadata": {},
   "source": [
    "We also weight the positive class (fraudulent) more than the negative class (genuine) to help account for the overrepresentation of genuine transactions in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd513a0",
   "metadata": {},
   "source": [
    "We then train and score an XGBoost classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long computation in this cell (~1.8 minutes)\n",
    "\n",
    "clf = XGBClassifier(max_depth = 3, scale_pos_weight = weights, n_jobs = 4, use_label_encoder=False)\n",
    "probabilities = clf.fit(trainX, trainY).predict_proba(testX)\n",
    "print('AUPRC = {}'.format(average_precision_score(testY, probabilities[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b06515d",
   "metadata": {},
   "source": [
    "We achieve a very impressive 0.99 AUPRC! Which means our classifier is accurately distinguishing between transactions. \n",
    "\n",
    "We can visualise the features which are most important to our new XGBoost classifier as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c7e90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (14, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colours = plt.cm.Set1(np.linspace(0, 1, 9))\n",
    "\n",
    "ax = plot_importance(clf, height = 1, color = colours, grid = False, \\\n",
    "                     show_values = False, importance_type = 'cover', ax = ax);\n",
    "for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(2)\n",
    "        \n",
    "ax.set_xlabel('importance score', size = 16);\n",
    "ax.set_ylabel('features', size = 16);\n",
    "ax.set_yticklabels(ax.get_yticklabels(), size = 12);\n",
    "ax.set_title('Plotting the models most important features', size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a94f89",
   "metadata": {},
   "source": [
    "We can now save our model, and upload it to an artefact store (in this case a Google storage bucket) ready for deployment.\n",
    "\n",
    "We will be making use of the pre-packaged XGBoost model server, and therefore Seldon expects our classifier to be saved as `model.bst`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275beb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('model.bst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36093c30",
   "metadata": {},
   "source": [
    "We will now upload our saved model file to a Google storage bucket. \n",
    "\n",
    "### !!! IMPORTANT !!!\n",
    "Make sure you fill in the WORKSHOP-NAME and YOUR-NAME to ensure you're not overwriting existing artefacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb251d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!gsutil cp model.bst gs://tom-seldon-examples/leit-workshop/tom/model.bst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50aae61",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "We can now deploy our model to the dedicated Seldon Deploy cluster which we have configured for this workshop. To do so we will interact with the Seldon Deploy SDK and deploy our model using that. \n",
    "\n",
    "First, setting up the configuration and authentication required to access the cluster. Make sure to fill in the `SD_IP` variable to be the same as the cluster you are using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SD_IP = \"46.101.65.30\"\n",
    "\n",
    "config = Configuration()\n",
    "config.host = f\"http://{SD_IP}/seldon-deploy/api/v1alpha1\"\n",
    "config.oidc_client_id = \"sd-api\"\n",
    "config.oidc_server = f\"http://{SD_IP}/auth/realms/deploy-realm\"\n",
    "\n",
    "def auth():\n",
    "    auth = OIDCAuthenticator(config)\n",
    "    config.access_token = auth.authenticate(\"admin@seldon.io\", \"12341234\")\n",
    "    api_client = ApiClient(config)\n",
    "    return api_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8915408",
   "metadata": {},
   "source": [
    "Now we have configured the IP correctly as well as setup our authentication function we can desrcibe the deployment we would like to create. \n",
    "\n",
    "You will need to fill in the `DEPLOYMENT_NAME`, `NAMESPACE`, and the `MODEL_LOCATION`, the rest of the deployment description has been templated for you. \n",
    "\n",
    "For the `MODEL_LOCATION` you do not need to specify the path all the way up to `model.bst` e.g. if you saved your classifier under `gs://tom-seldon-examples/my-workshop/tom/model.bst` your `MODEL_LOCATION` should be `gs://tom-seldon-examples/my-workshop/tom` and Seldon will automatically pick up the classifier artifact stored there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc49323",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_NAME = \"fraud-detector\"\n",
    "NAMESPACE = \"dev\"\n",
    "MODEL_LOCATION = \"gs://tom-seldon-examples/leit-workshop/tom\"\n",
    "\n",
    "PREPACKAGED_SERVER = \"XGBOOST_SERVER\"\n",
    "\n",
    "CPU_REQUESTS = \"1\"\n",
    "MEMORY_REQUESTS = \"1Gi\"\n",
    "\n",
    "CPU_LIMITS = \"1\"\n",
    "MEMORY_LIMITS = \"1Gi\"\n",
    "\n",
    "mldeployment = {\n",
    "    \"kind\": \"SeldonDeployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"namespace\": NAMESPACE,\n",
    "        \"labels\": {\n",
    "            \"fluentd\": \"true\"\n",
    "        }\n",
    "    },\n",
    "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
    "    \"spec\": {\n",
    "        \"name\": DEPLOYMENT_NAME,\n",
    "        \"annotations\": {\n",
    "            \"seldon.io/engine-seldon-log-messages-externally\": \"true\"\n",
    "        },\n",
    "        \"protocol\": \"seldon\",\n",
    "        \"transport\": \"rest\",\n",
    "        \"predictors\": [\n",
    "            {\n",
    "                \"componentSpecs\": [\n",
    "                    {\n",
    "                        \"spec\": {\n",
    "                            \"containers\": [\n",
    "                                {\n",
    "                                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                                    \"resources\": {\n",
    "                                        \"requests\": {\n",
    "                                            \"cpu\": CPU_REQUESTS,\n",
    "                                            \"memory\": MEMORY_REQUESTS\n",
    "                                        },\n",
    "                                        \"limits\": {\n",
    "                                            \"cpu\": CPU_LIMITS,\n",
    "                                            \"memory\": MEMORY_LIMITS\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"name\": \"default\",\n",
    "                \"replicas\": 1,\n",
    "                \"traffic\": 100,\n",
    "                \"graph\": {\n",
    "                    \"implementation\": PREPACKAGED_SERVER,\n",
    "                    \"modelUri\": MODEL_LOCATION,\n",
    "                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
    "                    \"endpoint\": {\n",
    "                        \"type\": \"REST\"\n",
    "                    },\n",
    "                    \"parameters\": [],\n",
    "                    \"children\": [],\n",
    "                    \"logger\": {\n",
    "                        \"mode\": \"all\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"status\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263e40c",
   "metadata": {},
   "source": [
    "We can now invoke the `SeldonDeploymentsApi` and create a new Seldon Deployment. \n",
    "\n",
    "Time for you to get your hands dirty. You will use the Seldon Deploy SDK to create a new Seldon deployment. You can find the reference documentation [here](https://github.com/SeldonIO/seldon-deploy-sdk/blob/master/python/README.md). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e347ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "# TO DO: Add in the correct API call to create a new seldon deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d37f0",
   "metadata": {},
   "source": [
    "We can now send requests to our model. As an example of a normal request:\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"names\": [\"step\", \"type\", \"amount\", \"oldBalanceOrig\", \"newBalanceOrig\",\n",
    "                  \"oldBalanceDest\", \"newBalanceDest\", \"errorBalanceOrig\", \"errorBalanceDest\"],\n",
    "        \"ndarray\": [\n",
    "            [205, 1, 63243.44, -1.00, -1.00, 1853683.32, 1916926.76, 63243.44, 0]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "And a fraudulent transaction too:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"names\": [\"step\", \"type\", \"amount\", \"oldBalanceOrig\", \"newBalanceOrig\",\n",
    "                  \"oldBalanceDest\", \"newBalanceDest\", \"errorBalanceOrig\", \"errorBalanceDest\"],\n",
    "        \"ndarray\": [\n",
    "            [629, 1, 2433009.28, 2433009.28, 0.00, 0.00, 2433009.28, 0.00, 0.00]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88995b",
   "metadata": {},
   "source": [
    "# Explainer\n",
    "Next, we shall train an explainer to glean deeper insights into the decisions being made by our model. \n",
    "\n",
    "We will make use of the Anchors algorithm, which has a [production grade implementation available](https://docs.seldon.io/projects/alibi/en/stable/methods/Anchors.html) using the Seldon Alibi Explain library. \n",
    "\n",
    "The first step will be to write a simple prediction function which the explainer can call in order to query our XGBoost model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(x):\n",
    "    return clf.predict_proba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ef3c1",
   "metadata": {},
   "source": [
    "We then initialise our Anchor explainer, using the AnchorTabular flavour provided by Alibi due to our data modality. \n",
    "\n",
    "The AnchorTabular class expects the prediction function which we defined above, as well as a list of the feature names. You can find a sample notebook in the Alibi docs [here](https://docs.seldon.io/projects/alibi/en/stable/examples/anchor_tabular_adult.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb19ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(trainX.columns)\n",
    "# TO DO: Use the predict_fn and feature_names to create a new explainer object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa4361",
   "metadata": {},
   "source": [
    "We now need to fit our explainer object around some data so that it can learn to generate explanations based upon said data. \n",
    "\n",
    "As our training set is highly imbalanced (only a tiny fraction of our datapoints are fraudulent transactions) we create a new balanced set which is 50/50 normal/fraud transactions. This helps us to generate descriptive and useful explanations for both fraudulent and normal transactions.*\n",
    "\n",
    "In the code block below we generate the new balanced set, and convert it to a numpy array as this is the type which Alibi expects. \n",
    "\n",
    "\\*It is possible to generate a working explainer based upon the original dataset, but the anchors it identifies are not specific when considering normal transactions. The empty anchor is only ever returned due to the skew in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e70f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_set = pd.concat([Xfraud, XnonFraud.iloc[:len(Xfraud)]]).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d325d3",
   "metadata": {},
   "source": [
    "We then fit our explainer to our balanced data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Fit our explainer with our balanced data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8516dbb",
   "metadata": {},
   "source": [
    "We can now test our explainer on the test set, and view the explanations it begins to generate. Feel free to change the value of `idx` to see how it impacts the explanation generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef5fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 10\n",
    "\n",
    "testX_array = testX.to_numpy()\n",
    "\n",
    "class_names = [\"Normal\", \"Fraudulent\"]\n",
    "print('Prediction: ', class_names[explainer.predictor(testX_array[idx].reshape(1, -1))[0]])\n",
    "\n",
    "explanation = explainer.explain(testX_array[idx], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1eb89",
   "metadata": {},
   "source": [
    "Explicitly testing a fraudulent transaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction: ', class_names[explainer.predictor(testX.loc[6272989].to_numpy().reshape(1, -1))[0]])\n",
    "\n",
    "explanation = explainer.explain(testX.loc[6272989].to_numpy(), threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048d98d",
   "metadata": {},
   "source": [
    "We now save our explainer, and upload it to the GS bucket. Your explainer must be saved as explainer.dill as once again Seldon Deploy will look for this artefact within a top level directory.\n",
    "\n",
    "NOTE: Dill is used to serialise the object instead of pickle as it offers a greater flexibilty in the object types which can be serialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6dde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(explainer, open( \"explainer.dill\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23afbf",
   "metadata": {},
   "source": [
    "Remember to fill in the WORKSHOP_NAME and YOUR_NAME in the command below. \n",
    "\n",
    "The explainer object which is generated is typically around 500MB and so can take a while to upload. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f3a7a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp explainer.dill gs://tom-seldon-examples/leit-workshop/tom/model.bst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4dfc54",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "We can now deploy our explainer alongside our model. First we define the explainer configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bcdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLAINER_TYPE = \"AnchorTabular\"\n",
    "EXPLAINER_URI = \"gs://tom-seldon-examples/leit-workshop/tom/\"\n",
    "\n",
    "explainer_spec = {\n",
    "                    \"type\": EXPLAINER_TYPE,\n",
    "                    \"modelUri\": EXPLAINER_URI,\n",
    "                    \"containerSpec\": {\n",
    "                        \"name\": \"\",\n",
    "                        \"resources\": {}\n",
    "                    }\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17064a7",
   "metadata": {},
   "source": [
    "We can then insert this additional configuration into our original `mldeployment` specification which we defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mldeployment['spec']['predictors'][0]['explainer'] = explainer_spec\n",
    "mldeployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c953922",
   "metadata": {},
   "source": [
    "We then deploy the explainer to our Seldon Deploy cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48439dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_api = SeldonDeploymentsApi(auth())\n",
    "# TO DO: Add in the correct API call to create a new seldon deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c988a0f",
   "metadata": {},
   "source": [
    "We can now use the same example requests as before to generate both a prediction and then a subsequent explanation. \n",
    "\n",
    "An example of a normal request:\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"names\": [\"step\", \"type\", \"amount\", \"oldBalanceOrig\", \"newBalanceOrig\",\n",
    "                  \"oldBalanceDest\", \"newBalanceDest\", \"errorBalanceOrig\", \"errorBalanceDest\"],\n",
    "        \"ndarray\": [\n",
    "            [205, 1, 63243.44, -1.00, -1.00, 1853683.32, 1916926.76, 63243.44, 0]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "A fraudulent transaction:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"data\": {\n",
    "        \"names\": [\"step\", \"type\", \"amount\", \"oldBalanceOrig\", \"newBalanceOrig\",\n",
    "                  \"oldBalanceDest\", \"newBalanceDest\", \"errorBalanceOrig\", \"errorBalanceDest\"],\n",
    "        \"ndarray\": [\n",
    "            [629, 1, 2433009.28, 2433009.28, 0.00, 0.00, 2433009.28, 0.00, 0.00]\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3076e1",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We have successfully cleaned and explored our dataset. We then trained an XGBoost classifier to distinguish between fraudulent and normal transactions which we subsequently saved and uploaded to a cloud storage bucket. We then deployed our model using the Seldon Deploy SDK, and used it to classify both a normal and a fraudlent transaction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
